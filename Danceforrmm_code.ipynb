{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T11:57:30.400791Z",
     "iopub.status.busy": "2025-01-30T11:57:30.400499Z",
     "iopub.status.idle": "2025-01-30T11:57:43.506623Z",
     "shell.execute_reply": "2025-01-30T11:57:43.505767Z",
     "shell.execute_reply.started": "2025-01-30T11:57:30.400767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "# Set TensorFlow to use GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # Iterate through physical GPUs\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth cannot be modified after GPU has been initialized\n",
    "        print(e)\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(rc={'axes.labelsize': 12, 'ytick.labelsize': 12, 'xtick.labelsize': 12, 'axes.titlesize': 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T11:57:43.508314Z",
     "iopub.status.busy": "2025-01-30T11:57:43.507685Z",
     "iopub.status.idle": "2025-01-30T11:57:43.645036Z",
     "shell.execute_reply": "2025-01-30T11:57:43.644147Z",
     "shell.execute_reply.started": "2025-01-30T11:57:43.508277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T11:57:53.938173Z",
     "iopub.status.busy": "2025-01-30T11:57:53.937893Z",
     "iopub.status.idle": "2025-01-30T11:57:53.942244Z",
     "shell.execute_reply": "2025-01-30T11:57:53.941355Z",
     "shell.execute_reply.started": "2025-01-30T11:57:53.938153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path(\"/kaggle/input/dancceforrmfff/Train\")\n",
    "test_dir = pathlib.Path(\"/kaggle/input/dancceforrmfff/Test\")\n",
    "#test_simple_dir = pathlib.Path(\"/kaggle/input/papayadata/valid\")\n",
    "\n",
    "#df = pd.read_csv(\"/kaggle/input/clssessss/_classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T11:57:56.331320Z",
     "iopub.status.busy": "2025-01-30T11:57:56.331037Z",
     "iopub.status.idle": "2025-01-30T11:57:56.340696Z",
     "shell.execute_reply": "2025-01-30T11:57:56.339940Z",
     "shell.execute_reply.started": "2025-01-30T11:57:56.331298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = os.listdir(train_dir)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T11:58:08.498686Z",
     "iopub.status.busy": "2025-01-30T11:58:08.498378Z",
     "iopub.status.idle": "2025-01-30T11:58:08.530769Z",
     "shell.execute_reply": "2025-01-30T11:58:08.529999Z",
     "shell.execute_reply.started": "2025-01-30T11:58:08.498664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train and test size\n",
    "image_count_train = len(list(train_dir.glob('*/*.png'))) + len(list(train_dir.glob('*/*.jpeg'))) + len(list(train_dir.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "\n",
    "image_count_test = len(list(test_dir.glob('*/*.png'))) + len(list(test_dir.glob('*/*.jpeg'))) + len(list(test_dir.glob('*/*.jpg')))\n",
    "print(image_count_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:01:15.992957Z",
     "iopub.status.busy": "2025-01-30T12:01:15.992677Z",
     "iopub.status.idle": "2025-01-30T12:01:16.293108Z",
     "shell.execute_reply": "2025-01-30T12:01:16.292374Z",
     "shell.execute_reply.started": "2025-01-30T12:01:15.992935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# Set TensorFlow to use GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # Iterate through physical GPUs\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth cannot be modified after GPU has been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# Your code to define class_names and train_dir goes here\n",
    "\n",
    "# Function to plot an image\n",
    "def plotImage(image_path):\n",
    "    img = plt.imread(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Loop through each class and plot an image\n",
    "for i in range(3): \n",
    "    class_images = list(train_dir.glob(class_names[i]+'/*.jpg')) + \\\n",
    "                   list(train_dir.glob(class_names[i]+'/*.png')) + \\\n",
    "                   list(train_dir.glob(class_names[i]+'/*.jpeg'))\n",
    "    if class_images:  # Check if images exist for this class\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        image_path = str(class_images[0])\n",
    "        if image_path.lower().endswith('.jpeg'):\n",
    "            img = Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "        else:\n",
    "            plotImage(image_path)\n",
    "        plt.title(class_names[i])\n",
    "        plt.grid()\n",
    "    else:\n",
    "        print(f\"No images found for class {class_names[i]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:01:26.534157Z",
     "iopub.status.busy": "2025-01-30T12:01:26.533869Z",
     "iopub.status.idle": "2025-01-30T12:01:27.187211Z",
     "shell.execute_reply": "2025-01-30T12:01:27.186324Z",
     "shell.execute_reply.started": "2025-01-30T12:01:26.534135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(3): \n",
    "    # Get image paths for the current class\n",
    "    image_paths = list(train_dir.glob(class_names[i]+'/*.jpg')) + \\\n",
    "                  list(train_dir.glob(class_names[i]+'/*.bmp')) + \\\n",
    "                  list(train_dir.glob(class_names[i]+'/*.png'))\n",
    "\n",
    "    # Check if there are any images for the current class\n",
    "    if not image_paths:\n",
    "        print(f\"No images found for class: {class_names[i]}\")\n",
    "        continue  # Skip to the next class\n",
    "\n",
    "    # Plot the first image for the current class\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plotImage(str(image_paths[0]))  # Plot the first image path\n",
    "    plt.title(class_names[i])\n",
    "    plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:01:44.319697Z",
     "iopub.status.busy": "2025-01-30T12:01:44.319272Z",
     "iopub.status.idle": "2025-01-30T12:01:56.724941Z",
     "shell.execute_reply": "2025-01-30T12:01:56.723572Z",
     "shell.execute_reply.started": "2025-01-30T12:01:44.319666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Directories for training and testing data\n",
    "train_dir = pathlib.Path(\"/kaggle/input/dancceforrmfff/Train\")\n",
    "test_dir = pathlib.Path(\"/kaggle/input/dancceforrmfff/Test\")\n",
    "\n",
    "# Helper function to load and preprocess a single image\n",
    "def load_and_preprocess_image(image_path, target_size=(120, 120)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "    return img, img_array\n",
    "\n",
    "# Load images from all subdirectories (classes)\n",
    "def load_images_from_all_classes(dir_path, sample_size=5):\n",
    "    all_image_paths = []\n",
    "    for subdir in dir_path.iterdir():\n",
    "        if subdir.is_dir():\n",
    "            class_images = list(subdir.glob(\"*.jpg\"))\n",
    "            all_image_paths.extend(class_images[:sample_size])  # Sample a few images from each class\n",
    "    return all_image_paths\n",
    "\n",
    "# Get a few images for visualization\n",
    "train_images = load_images_from_all_classes(train_dir, sample_size=5)\n",
    "\n",
    "# Apply different preprocessing techniques\n",
    "def apply_preprocessing(img_array):\n",
    "    # Resize\n",
    "    resized = tf.image.resize(img_array, [64, 64])\n",
    "\n",
    "    # Flip horizontally\n",
    "    flipped = tf.image.flip_left_right(img_array)\n",
    "\n",
    "    # Adjust brightness\n",
    "    brightened = tf.image.adjust_brightness(img_array, delta=0.2)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    noise = tf.random.normal(shape=img_array.shape, mean=0.0, stddev=0.05)\n",
    "    noisy = tf.clip_by_value(img_array + noise, 0.0, 1.0)\n",
    "\n",
    "    # Rotation (90 degrees)\n",
    "    rotated = tf.image.rot90(img_array)\n",
    "\n",
    "    return resized, flipped, brightened, noisy, rotated\n",
    "\n",
    "# Plot results\n",
    "def visualize_preprocessing(image_paths):\n",
    "    plt.figure(figsize=(35, 30))\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # Load image and preprocess\n",
    "        img, img_array = load_and_preprocess_image(image_path)\n",
    "\n",
    "        # Apply preprocessing\n",
    "        resized, flipped, brightened, noisy, rotated = apply_preprocessing(img_array)\n",
    "\n",
    "        # Plot original and preprocessed images\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 1)\n",
    "        plt.imshow(img_array)  # Use the normalized NumPy array\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 2)\n",
    "        plt.imshow(resized.numpy())\n",
    "        plt.title(\"Resized\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 3)\n",
    "        plt.imshow(flipped.numpy())\n",
    "        plt.title(\"Flipped\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 4)\n",
    "        plt.imshow(brightened.numpy())\n",
    "        plt.title(\"Brightened\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 5)\n",
    "        plt.imshow(noisy.numpy())\n",
    "        plt.title(\"Noisy\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 6)\n",
    "        plt.imshow(rotated.numpy())\n",
    "        plt.title(\"Rotated\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize preprocessing on train images\n",
    "visualize_preprocessing(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:07.800103Z",
     "iopub.status.busy": "2025-01-30T12:02:07.799791Z",
     "iopub.status.idle": "2025-01-30T12:02:12.696261Z",
     "shell.execute_reply": "2025-01-30T12:02:12.695267Z",
     "shell.execute_reply.started": "2025-01-30T12:02:07.800078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Directories for training and testing data\n",
    "train_dir = pathlib.Path(\"/kaggle/input/dancceforrmfff/Train\")\n",
    "test_dir = pathlib.Path(\"/kaggle/input/dancceforrmfff/Test\")\n",
    "\n",
    "# Helper function to load and preprocess a single image\n",
    "def load_and_preprocess_image(image_path, target_size=(120, 120)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "    return img, img_array\n",
    "\n",
    "# Select a few images for visualization\n",
    "train_images = list(train_dir.glob(\"*/*.jpg\"))[:5]\n",
    "\n",
    "# Apply different preprocessing techniques\n",
    "def apply_preprocessing(img_array):\n",
    "    # Resize\n",
    "    resized = tf.image.resize(img_array, [64, 64])\n",
    "\n",
    "    # Flip horizontally\n",
    "    flipped = tf.image.flip_left_right(img_array)\n",
    "\n",
    "    # Adjust brightness\n",
    "    brightened = tf.image.adjust_brightness(img_array, delta=0.2)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    noise = tf.random.normal(shape=img_array.shape, mean=0.0, stddev=0.05)\n",
    "    noisy = tf.clip_by_value(img_array + noise, 0.0, 1.0)\n",
    "\n",
    "    # Rotation (90 degrees)\n",
    "    rotated = tf.image.rot90(img_array)\n",
    "\n",
    "    return resized, flipped, brightened, noisy, rotated\n",
    "\n",
    "# Plot results\n",
    "def visualize_preprocessing(image_paths):\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # Load image and preprocess\n",
    "        img, img_array = load_and_preprocess_image(image_path)\n",
    "\n",
    "        # Apply preprocessing\n",
    "        resized, flipped, brightened, noisy, rotated = apply_preprocessing(img_array)\n",
    "\n",
    "        # Plot original and preprocessed images\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 1)\n",
    "        plt.imshow(img_array)  # Use the normalized NumPy array\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 2)\n",
    "        plt.imshow(resized.numpy())\n",
    "        plt.title(\"Resized\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 3)\n",
    "        plt.imshow(flipped.numpy())\n",
    "        plt.title(\"Flipped\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 4)\n",
    "        plt.imshow(brightened.numpy())\n",
    "        plt.title(\"Brightened\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 5)\n",
    "        plt.imshow(noisy.numpy())\n",
    "        plt.title(\"Noisy\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(len(image_paths), 6, idx * 6 + 6)\n",
    "        plt.imshow(rotated.numpy())\n",
    "        plt.title(\"Rotated\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize preprocessing on train images\n",
    "visualize_preprocessing(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:15.023071Z",
     "iopub.status.busy": "2025-01-30T12:02:15.022756Z",
     "iopub.status.idle": "2025-01-30T12:02:15.036094Z",
     "shell.execute_reply": "2025-01-30T12:02:15.035315Z",
     "shell.execute_reply.started": "2025-01-30T12:02:15.023043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Training samples:')\n",
    "num_samples = 0\n",
    "for cell in os.listdir(train_dir):\n",
    "    num_cells = len(os.listdir(os.path.join(train_dir, cell)))\n",
    "    num_samples += num_cells\n",
    "    print('Cell: {:15s}  num samples: {:d}'.format(cell, num_cells))\n",
    "print('Total training samples: {:d}\\n'.format(num_samples))\n",
    "\n",
    "print('Test samples:')\n",
    "num_samples = 0\n",
    "for cell in os.listdir(test_dir):\n",
    "    num_cells = len(os.listdir(os.path.join(test_dir, cell)))\n",
    "    num_samples += num_cells\n",
    "    print('Cell: {:15s}  num samples: {:d}'.format(cell, num_cells))\n",
    "print('Total test samples: {:d}'.format(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:19.970588Z",
     "iopub.status.busy": "2025-01-30T12:02:19.970260Z",
     "iopub.status.idle": "2025-01-30T12:02:19.975546Z",
     "shell.execute_reply": "2025-01-30T12:02:19.974702Z",
     "shell.execute_reply.started": "2025-01-30T12:02:19.970562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# function to plot the training/validation accuracies/losses.\n",
    "\n",
    "def plot_learning(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    #axes[0].grid()\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "    axes[1].plot(history.history['accuracy'])   \n",
    "    axes[1].plot(history.history['val_accuracy'])\n",
    "    #axes[1].grid()\n",
    "    axes[1].legend(['accuracy','val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:22.634613Z",
     "iopub.status.busy": "2025-01-30T12:02:22.634284Z",
     "iopub.status.idle": "2025-01-30T12:02:22.645944Z",
     "shell.execute_reply": "2025-01-30T12:02:22.645235Z",
     "shell.execute_reply.started": "2025-01-30T12:02:22.634586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# resolution of images\n",
    "plt.imread(str(list(train_dir.glob(class_names[i]+'/*.jpg'))[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:24.465718Z",
     "iopub.status.busy": "2025-01-30T12:02:24.465390Z",
     "iopub.status.idle": "2025-01-30T12:02:24.469332Z",
     "shell.execute_reply": "2025-01-30T12:02:24.468692Z",
     "shell.execute_reply.started": "2025-01-30T12:02:24.465694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# defining some parameters for the loader\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 120\n",
    "img_width = 120\n",
    "\n",
    "# lower resolution images reduce the definition/clarity of certain features in images.\n",
    "# It can make it harder for CNN to learn the features required for classification or detection.\n",
    "# working with 120 x 120 resolution images for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:26.309759Z",
     "iopub.status.busy": "2025-01-30T12:02:26.309425Z",
     "iopub.status.idle": "2025-01-30T12:02:26.326957Z",
     "shell.execute_reply": "2025-01-30T12:02:26.326073Z",
     "shell.execute_reply.started": "2025-01-30T12:02:26.309729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"GPU is available\")\n",
    "    # Set memory growth for GPU\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize Adam optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# Define loss function\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:28.433181Z",
     "iopub.status.busy": "2025-01-30T12:02:28.432897Z",
     "iopub.status.idle": "2025-01-30T12:02:31.251077Z",
     "shell.execute_reply": "2025-01-30T12:02:31.250429Z",
     "shell.execute_reply.started": "2025-01-30T12:02:28.433159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=21,\n",
    "    validation_split= 0.15,\n",
    "    subset= 'training',\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:31.252504Z",
     "iopub.status.busy": "2025-01-30T12:02:31.252188Z",
     "iopub.status.idle": "2025-01-30T12:02:31.443053Z",
     "shell.execute_reply": "2025-01-30T12:02:31.442455Z",
     "shell.execute_reply.started": "2025-01-30T12:02:31.252475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=21,\n",
    "    validation_split= 0.12,\n",
    "    subset= 'validation',\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:31.825883Z",
     "iopub.status.busy": "2025-01-30T12:02:31.825593Z",
     "iopub.status.idle": "2025-01-30T12:02:32.294674Z",
     "shell.execute_reply": "2025-01-30T12:02:32.293679Z",
     "shell.execute_reply.started": "2025-01-30T12:02:31.825862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:32.296505Z",
     "iopub.status.busy": "2025-01-30T12:02:32.296128Z",
     "iopub.status.idle": "2025-01-30T12:02:32.305292Z",
     "shell.execute_reply": "2025-01-30T12:02:32.304319Z",
     "shell.execute_reply.started": "2025-01-30T12:02:32.296467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()\n",
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:33.866441Z",
     "iopub.status.busy": "2025-01-30T12:02:33.866133Z",
     "iopub.status.idle": "2025-01-30T12:02:33.870101Z",
     "shell.execute_reply": "2025-01-30T12:02:33.869351Z",
     "shell.execute_reply.started": "2025-01-30T12:02:33.866414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:02:34.256295Z",
     "iopub.status.busy": "2025-01-30T12:02:34.256008Z",
     "iopub.status.idle": "2025-01-30T12:02:34.260003Z",
     "shell.execute_reply": "2025-01-30T12:02:34.259232Z",
     "shell.execute_reply.started": "2025-01-30T12:02:34.256272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_disable_xla_devices'\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCEPTION V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# defining some parameters for the loader\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 120\n",
    "img_width = 120\n",
    "\n",
    "# lower resolution images reduce the definition/clarity of certain features in images.\n",
    "# It can make it harder for CNN to learn the features required for classification or detection.\n",
    "# working with 120 x 120 resolution images for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, BatchNormalization, ReLU, Dropout\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Define input shape and number of classes\n",
    "input_shape = (120, 120, 3)  # Define your input shape\n",
    "num_classes = 3\n",
    "\n",
    "# Define a more complex InceptionV3 model with additional layers\n",
    "def create_minimal_inception_v3(input_shape=input_shape):\n",
    "    \"\"\"\n",
    "    Builds a more complex InceptionV3 model for multi-class classification with additional dense layers up to 2048 units.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # Load the InceptionV3 model (using no pre-trained weights)\n",
    "    base_model = InceptionV3(weights=None, include_top=False, input_shape=input_shape)(input_tensor)\n",
    "\n",
    "    # Freeze InceptionV3 layers\n",
    "    base_model.trainable = False  # Freeze layers initially\n",
    "\n",
    "    # Add a Global Average Pooling layer\n",
    "    x = GlobalAveragePooling2D()(base_model)\n",
    "\n",
    "    # Add dense layers with increasing units and dropout for regularization\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Dense(2048, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Add more dense layers for further capacity\n",
    "    x = Dense(4096, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Add another dense layer\n",
    "    x = Dense(2048, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Output layer\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_minimal_inception_v3()\n",
    "\n",
    "# Compile the model with a higher learning rate\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# You can now train the model using `model.fit()` with the appropriate training and validation data.\n",
    "# Add early stopping and model checkpoint callbacks\n",
    "\n",
    "\n",
    "\n",
    "# Correct ModelCheckpoint usage by adding a filepath argument\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "#checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Assuming you have train_data, train_labels, val_data, and val_labels\n",
    "# model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=50, \n",
    "#           validation_data=(val_data, val_labels), \n",
    "#           callbacks=[early_stopping, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:23.322317Z",
     "iopub.status.busy": "2025-01-29T10:43:23.322019Z",
     "iopub.status.idle": "2025-01-29T10:43:23.330534Z",
     "shell.execute_reply": "2025-01-29T10:43:23.329581Z",
     "shell.execute_reply.started": "2025-01-29T10:43:23.322295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"GPU is available\")\n",
    "    # Set memory growth for GPU\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize Adam optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# Specify loss function\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:25.221517Z",
     "iopub.status.busy": "2025-01-29T10:43:25.221194Z",
     "iopub.status.idle": "2025-01-29T10:43:25.225144Z",
     "shell.execute_reply": "2025-01-29T10:43:25.224367Z",
     "shell.execute_reply.started": "2025-01-29T10:43:25.221492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:32.138851Z",
     "iopub.status.busy": "2025-01-29T10:43:32.138520Z",
     "iopub.status.idle": "2025-01-29T10:43:32.143206Z",
     "shell.execute_reply": "2025-01-29T10:43:32.142289Z",
     "shell.execute_reply.started": "2025-01-29T10:43:32.138825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.2,           # Reduce learning rate by half\n",
    "    patience=3,           # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=0.00001,          # Minimum learning rate allowed\n",
    "    verbose=1             # Print a message when the learning rate is reduced\n",
    ")\n",
    "callbacks = [lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:33.851485Z",
     "iopub.status.busy": "2025-01-29T10:43:33.851166Z",
     "iopub.status.idle": "2025-01-29T10:43:33.855475Z",
     "shell.execute_reply": "2025-01-29T10:43:33.854682Z",
     "shell.execute_reply.started": "2025-01-29T10:43:33.851462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable graph optimization\n",
    "tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:36.022514Z",
     "iopub.status.busy": "2025-01-29T10:43:36.022204Z",
     "iopub.status.idle": "2025-01-29T10:43:36.028165Z",
     "shell.execute_reply": "2025-01-29T10:43:36.027282Z",
     "shell.execute_reply.started": "2025-01-29T10:43:36.022492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:36.444077Z",
     "iopub.status.busy": "2025-01-29T10:43:36.443760Z",
     "iopub.status.idle": "2025-01-29T10:43:36.447878Z",
     "shell.execute_reply": "2025-01-29T10:43:36.447015Z",
     "shell.execute_reply.started": "2025-01-29T10:43:36.444052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set GPU memory growth to avoid memory fragmentation issues\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:38.201414Z",
     "iopub.status.busy": "2025-01-29T10:43:38.201079Z",
     "iopub.status.idle": "2025-01-29T10:43:38.205408Z",
     "shell.execute_reply": "2025-01-29T10:43:38.204505Z",
     "shell.execute_reply.started": "2025-01-29T10:43:38.201387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"All log messages before absl::InitializeLog()\")\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:43:40.582102Z",
     "iopub.status.busy": "2025-01-29T10:43:40.581765Z",
     "iopub.status.idle": "2025-01-29T10:50:25.307658Z",
     "shell.execute_reply": "2025-01-29T10:50:25.306717Z",
     "shell.execute_reply.started": "2025-01-29T10:43:40.582075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"GPU is available\")\n",
    "    # Set memory growth for GPU\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize Adam optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# Specify loss function\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "history_model_v3 = model.fit(\n",
    "                    train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    #steps_per_epoch=300,\n",
    "                    epochs=epochs,\n",
    "                   # callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:25.309293Z",
     "iopub.status.busy": "2025-01-29T10:50:25.308976Z",
     "iopub.status.idle": "2025-01-29T10:50:25.764060Z",
     "shell.execute_reply": "2025-01-29T10:50:25.763252Z",
     "shell.execute_reply.started": "2025-01-29T10:50:25.309262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning(history_model_v3):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss with different colors.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_model_v3.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history_model_v3.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_model_v3.history['loss'], label='Train Loss', color='red')\n",
    "    plt.plot(history_model_v3.history['val_loss'], label='Validation Loss', color='purple')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning(history_model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:25.766174Z",
     "iopub.status.busy": "2025-01-29T10:50:25.765915Z",
     "iopub.status.idle": "2025-01-29T10:50:26.213950Z",
     "shell.execute_reply": "2025-01-29T10:50:26.213179Z",
     "shell.execute_reply.started": "2025-01-29T10:50:25.766154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_learning(history_model_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:26.215509Z",
     "iopub.status.busy": "2025-01-29T10:50:26.215283Z",
     "iopub.status.idle": "2025-01-29T10:50:26.221265Z",
     "shell.execute_reply": "2025-01-29T10:50:26.220461Z",
     "shell.execute_reply.started": "2025-01-29T10:50:26.215489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:26.222430Z",
     "iopub.status.busy": "2025-01-29T10:50:26.222135Z",
     "iopub.status.idle": "2025-01-29T10:50:29.963278Z",
     "shell.execute_reply": "2025-01-29T10:50:29.962436Z",
     "shell.execute_reply.started": "2025-01-29T10:50:26.222398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluating performance on test set\n",
    "\n",
    "results = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss of the model  is - test \", results[0])\n",
    "print(\"Accuracy of the model is - test\", results[1]*100, \"%\\n\")\n",
    "\n",
    "\n",
    "results = model.evaluate(val_ds)\n",
    "\n",
    "print(\"Loss of the model  is - val \", results[0])\n",
    "print(\"Accuracy of the model is - val\", results[1]*100, \"%\\n\")\n",
    "\n",
    "results = model.evaluate(train_ds)\n",
    "\n",
    "print(\"Loss of the model  is - train \", results[0])\n",
    "print(\"Accuracy of the model is - train\", results[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:29.964433Z",
     "iopub.status.busy": "2025-01-29T10:50:29.964202Z",
     "iopub.status.idle": "2025-01-29T10:50:31.608755Z",
     "shell.execute_reply": "2025-01-29T10:50:31.607774Z",
     "shell.execute_reply.started": "2025-01-29T10:50:29.964413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = np.array([])\n",
    "labels =  np.array([])\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x, verbose=0),axis=1)\n",
    "    predictions = np.concatenate([predictions, y_pred])\n",
    "    labels = np.concatenate([labels, y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:31.610082Z",
     "iopub.status.busy": "2025-01-29T10:50:31.609756Z",
     "iopub.status.idle": "2025-01-29T10:50:31.623821Z",
     "shell.execute_reply": "2025-01-29T10:50:31.622666Z",
     "shell.execute_reply.started": "2025-01-29T10:50:31.610050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(labels,predictions,\n",
    "                           target_names = ['china fan dance', 'Sword Dance', 'dragon dance images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:31.626142Z",
     "iopub.status.busy": "2025-01-29T10:50:31.625919Z",
     "iopub.status.idle": "2025-01-29T10:50:35.277616Z",
     "shell.execute_reply": "2025-01-29T10:50:35.276715Z",
     "shell.execute_reply.started": "2025-01-29T10:50:31.626122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Replace with actual class names)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of rows and columns for the grid\n",
    "rows, cols = 4, 4  \n",
    "\n",
    "# Take a batch of images and labels from the dataset\n",
    "for images, labels in test_ds.take(1):  # Take only one batch\n",
    "    plt.figure(figsize=(12, 12))  # Set figure size\n",
    "\n",
    "    for i in range(min(rows * cols, len(images))):  # Ensure it doesn't exceed dataset size\n",
    "        plt.subplot(rows, cols, i + 1)  # Create a 4-row, 4-column subplot\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert image to uint8 format\n",
    "        plt.axis(\"off\")  # Hide axes\n",
    "\n",
    "        # Get model predictions\n",
    "        predictions = model.predict(images[i][None, ...])  # Get prediction probabilities\n",
    "        predicted_class = np.argmax(predictions)  # Get class index\n",
    "        confidence = np.max(predictions) * 100  # Get confidence in percentage\n",
    "\n",
    "        # Set title with class name and confidence\n",
    "        plt.title(f\"{class_names[predicted_class]}\\n{confidence:.2f}%\", fontsize=10, color=\"red\")\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()  # Display the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:35.279283Z",
     "iopub.status.busy": "2025-01-29T10:50:35.279032Z",
     "iopub.status.idle": "2025-01-29T10:50:35.558321Z",
     "shell.execute_reply": "2025-01-29T10:50:35.557476Z",
     "shell.execute_reply.started": "2025-01-29T10:50:35.279261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for images, labels in test_ds.take(2):\n",
    "    plt.imshow(images[0].numpy().astype(\"uint8\"))\n",
    "    print(images.shape)\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:35.559388Z",
     "iopub.status.busy": "2025-01-29T10:50:35.559142Z",
     "iopub.status.idle": "2025-01-29T10:50:35.562912Z",
     "shell.execute_reply": "2025-01-29T10:50:35.562094Z",
     "shell.execute_reply.started": "2025-01-29T10:50:35.559349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:35.563824Z",
     "iopub.status.busy": "2025-01-29T10:50:35.563612Z",
     "iopub.status.idle": "2025-01-29T10:50:36.193506Z",
     "shell.execute_reply": "2025-01-29T10:50:36.192794Z",
     "shell.execute_reply.started": "2025-01-29T10:50:35.563804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize empty lists for true labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through the test dataset to obtain predictions\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x), axis=1)\n",
    "    true_labels.extend(y.numpy())\n",
    "    predicted_labels.extend(y_pred)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "#print(classification_report(true_labels, predicted_labels,\n",
    "#                            target_names=[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:50:36.194426Z",
     "iopub.status.busy": "2025-01-29T10:50:36.194217Z",
     "iopub.status.idle": "2025-01-29T10:50:36.464998Z",
     "shell.execute_reply": "2025-01-29T10:50:36.464248Z",
     "shell.execute_reply.started": "2025-01-29T10:50:36.194407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix (cm):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        cmap = 'Blues', \n",
    "        linecolor = 'black', \n",
    "        linewidth = 1, \n",
    "        annot = True, \n",
    "        fmt = '', \n",
    "        xticklabels = class_names, \n",
    "        yticklabels = class_names)\n",
    "    \n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T14:00:12.387309Z",
     "iopub.status.busy": "2025-01-29T14:00:12.387017Z",
     "iopub.status.idle": "2025-01-29T14:00:12.577295Z",
     "shell.execute_reply": "2025-01-29T14:00:12.576363Z",
     "shell.execute_reply.started": "2025-01-29T14:00:12.387286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix_3d(cm, class_names):\n",
    "    \"\"\"\n",
    "    Plots a 3D surface plot for the confusion matrix.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create the X and Y grid for the confusion matrix\n",
    "    x, y = np.meshgrid(np.arange(cm.shape[0]), np.arange(cm.shape[1]))\n",
    "\n",
    "    # Plotting the surface\n",
    "    ax.plot_surface(x, y, cm, cmap='Blues', edgecolor='black', linewidth=1)\n",
    "\n",
    "    # Annotate the surface with text (values from the confusion matrix)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(x[i, j], y[i, j], cm[i, j], str(cm[i, j]), color='black', fontsize=12, ha='center')\n",
    "\n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_zlabel('Count')\n",
    "\n",
    "    # Set ticks for X and Y axes based on class names\n",
    "    ax.set_xticks(np.arange(cm.shape[1]))\n",
    "    ax.set_yticks(np.arange(cm.shape[0]))\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title('Confusion Matrix in 3D')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "#[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]\n",
    "# Example usage:\n",
    "# Assuming you have a confusion matrix `cm` and class names in `class_names`\n",
    "class_names = ['china fan dance', 'Sword Dance', 'dragon dance images']  # Modify with your actual class names\n",
    "plot_confusion_matrix_3d(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:36:32.881466Z",
     "iopub.status.busy": "2025-01-29T12:36:32.881124Z",
     "iopub.status.idle": "2025-01-29T12:36:33.398874Z",
     "shell.execute_reply": "2025-01-29T12:36:33.398002Z",
     "shell.execute_reply.started": "2025-01-29T12:36:32.881442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Modify based on your dataset)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of epochs for plotting (replace with actual epoch count)\n",
    "epochs = np.arange(1, 11)  # Example: 10 epochs\n",
    "\n",
    "# Create a larger plot\n",
    "fig, ax = plt.subplots(figsize=(16, 12))  # Enlarged plot size\n",
    "\n",
    "# Set labels for axes and title\n",
    "ax.set_xlabel('Epochs', fontsize=14, weight='bold')\n",
    "ax.set_ylabel('Confidence (%)', fontsize=14, weight='bold')\n",
    "ax.set_title('Model Accuracy with Confidence Bubbles', fontsize=16, weight='bold')\n",
    "\n",
    "# Variables to store bubble data\n",
    "x_data = []\n",
    "y_data = []\n",
    "sizes = []  # Bubble sizes (confidence or any other measure)\n",
    "colors = []  # Bubble colors (can represent confidence)\n",
    "\n",
    "# Generate random data for demonstration\n",
    "# Replace this section with real model predictions for each epoch\n",
    "for epoch in epochs:\n",
    "    for class_idx in range(len(class_names)):\n",
    "        # Simulating confidence for each class in each epoch\n",
    "        confidence = np.random.uniform(0.60, 1.00) * 100  # Random confidence between 60 and 100%\n",
    "        \n",
    "        # Store the data for plotting\n",
    "        x_data.append(epoch)\n",
    "        y_data.append(confidence)\n",
    "        sizes.append(confidence * 25)  # Increased bubble size (scaled more)\n",
    "        colors.append(confidence)  # Set color based on confidence\n",
    "\n",
    "# Scatter plot with bubbles\n",
    "scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='plasma', alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Add color bar for confidence\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='Confidence %')\n",
    "cbar.set_ticks([0, 25, 50, 75, 100])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Adjust spacing for labels to avoid overlap and keep labels inside the plot\n",
    "for i in range(len(x_data)):\n",
    "    # Offset y-position to avoid going outside the plotting area\n",
    "    label_x = x_data[i]\n",
    "    label_y = y_data[i] + 5  # Adjust this offset if necessary\n",
    "\n",
    "    # Check if the label is too close to the top or bottom and adjust\n",
    "    if label_y > 100:  # If label goes above the upper limit\n",
    "        label_y = 95  # Place label a little below 100\n",
    "    elif label_y < 10:  # If label is too close to the bottom\n",
    "        label_y = 15  # Place label a little above 0\n",
    "    \n",
    "    ax.text(label_x, label_y, f'{class_names[x_data[i] % len(class_names)]}\\n{y_data[i]:.1f}%', \n",
    "            ha='center', fontsize=8, color='black', weight='bold', fontstyle='italic', \n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))  # Background for better readability\n",
    "\n",
    "# Adjusting grid for better presentation\n",
    "ax.set_xticks(epochs)\n",
    "ax.set_yticks(np.arange(0, 110, 10))\n",
    "ax.set_yticklabels(np.arange(0, 110, 10), fontsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Increase space between labels and bubbles\n",
    "ax.margins(x=0.05, y=0.1)\n",
    "\n",
    "# Tight layout to prevent overlap\n",
    "plt.tight_layout(pad=5.0)  # Increased padding for better spacing\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T11:56:59.507691Z",
     "iopub.status.busy": "2025-01-29T11:56:59.507378Z",
     "iopub.status.idle": "2025-01-29T11:56:59.953087Z",
     "shell.execute_reply": "2025-01-29T11:56:59.952220Z",
     "shell.execute_reply.started": "2025-01-29T11:56:59.507668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles(history_model_v3):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v3.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v3.history['accuracy'],\n",
    "        'val': history_model_v3.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 2D plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for start, end in epoch_ranges:\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with Bubbles')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles(history_model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T11:58:05.552000Z",
     "iopub.status.busy": "2025-01-29T11:58:05.551627Z",
     "iopub.status.idle": "2025-01-29T11:58:07.000693Z",
     "shell.execute_reply": "2025-01-29T11:58:06.999706Z",
     "shell.execute_reply.started": "2025-01-29T11:58:05.551960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles_separated(history_model_v3):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v3.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v3.history['accuracy'],\n",
    "        'val': history_model_v3.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Variables to store bubble data\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        sizes = []  # Bubble sizes (based on accuracy)\n",
    "        colors = []  # Bubble colors (for visualization)\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "        # Scatter plot with bubbles\n",
    "        scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add color bar for accuracy\n",
    "        plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles_separated(history_model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:19:02.474211Z",
     "iopub.status.busy": "2025-01-29T12:19:02.473865Z",
     "iopub.status.idle": "2025-01-29T12:19:03.601056Z",
     "shell.execute_reply": "2025-01-29T12:19:03.600229Z",
     "shell.execute_reply.started": "2025-01-29T12:19:02.474186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_solid_lines(history_model_v3):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100),\n",
    "    using solid lines to represent the accuracies.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v3.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v3.history['accuracy'],\n",
    "        'val': history_model_v3.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Plot the lines for training and validation accuracy with new colors\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Training Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='darkorange', linewidth=3)\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='mediumseagreen', linewidth=3)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_solid_lines(history_model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:21:42.832453Z",
     "iopub.status.busy": "2025-01-29T12:21:42.832145Z",
     "iopub.status.idle": "2025-01-29T12:21:43.212120Z",
     "shell.execute_reply": "2025-01-29T12:21:43.211221Z",
     "shell.execute_reply.started": "2025-01-29T12:21:42.832431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def plot_accuracy_with_3d_lines(history_model_v3):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate 3D subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    Adds enhancements such as color gradients for a stunning 3D effect.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v3.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v3.history['accuracy'],\n",
    "        'val': history_model_v3.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a figure for the 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')  # 3D subplot\n",
    "    \n",
    "    # Set the colormap and normalize the values for color gradients\n",
    "    cmap = cm.viridis  # You can change this to any other colormap such as 'plasma', 'inferno', etc.\n",
    "    norm = Normalize(vmin=1, vmax=100)\n",
    "\n",
    "    # Loop through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Color gradient based on epoch number\n",
    "        train_colors = cmap(norm(epoch_range))  # Apply colormap to training accuracy\n",
    "        val_colors = cmap(norm(epoch_range))    # Apply colormap to validation accuracy\n",
    "\n",
    "        # 3D plot for training accuracy\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=1, label=f'Training Accuracy (Epochs {start}-{end})', marker='o', color=train_colors[-1], linewidth=3, markersize=8)\n",
    "        \n",
    "        # 3D plot for validation accuracy\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=2, label=f'Validation Accuracy (Epochs {start}-{end})', marker='^', color=val_colors[-1], linewidth=3, markersize=8)\n",
    "\n",
    "    # Set labels with improved styling\n",
    "    ax.set_xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.set_zlabel('Accuracy Level', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Set title with improved styling\n",
    "    ax.set_title('Training and Validation Accuracy in 3D', fontsize=16, fontweight='bold', color='darkblue')\n",
    "\n",
    "    # Customize the grid and background for better aesthetics\n",
    "    ax.grid(True, color='gray', linestyle='--', linewidth=0.5)\n",
    "    ax.set_facecolor('whitesmoke')\n",
    "    \n",
    "    # Adjust the view angle for better clarity\n",
    "    ax.view_init(30, 45)\n",
    "\n",
    "    # Add a legend with better positioning\n",
    "    ax.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_lines(history_model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:22:46.267194Z",
     "iopub.status.busy": "2025-01-29T12:22:46.266815Z",
     "iopub.status.idle": "2025-01-29T12:22:46.698961Z",
     "shell.execute_reply": "2025-01-29T12:22:46.698022Z",
     "shell.execute_reply.started": "2025-01-29T12:22:46.267163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_accuracy_with_3d_bubbles(history_model_v3):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with 3D bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v3.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v3.history['accuracy'],\n",
    "        'val': history_model_v3.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_zlabel('Accuracy Level')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    z_data = []  # Z-axis for different epoch ranges\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            z_data.append(idx + 1)  # Different z values based on epoch range (1, 2, 3, 4)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles (for train and validation accuracy)\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=idx + 1, label=f'Train Accuracy (Epochs {start}-{end})', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=idx + 1, label=f'Validation Accuracy (Epochs {start}-{end})', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, z_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with 3D Bubbles', fontsize=16, fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_bubbles(history_model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:24:00.717730Z",
     "iopub.status.busy": "2025-01-29T12:24:00.717417Z",
     "iopub.status.idle": "2025-01-29T12:24:01.113559Z",
     "shell.execute_reply": "2025-01-29T12:24:01.112592Z",
     "shell.execute_reply.started": "2025-01-29T12:24:00.717707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_learning_3d(history_model_v3):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss in 3D.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v3.history['accuracy']) + 1)\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # First 3D subplot for accuracy\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.plot(epochs, history_model_v3.history['accuracy'], zs=1, label='Train Accuracy', color='blue', linewidth=2)\n",
    "    ax1.plot(epochs, history_model_v3.history['val_accuracy'], zs=2, label='Validation Accuracy', color='green', linewidth=2)\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_zlabel(\"Type\")\n",
    "    ax1.set_title(\"Training and Validation Accuracy in 3D\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Second 3D subplot for loss\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.plot(epochs, history_model_v3.history['loss'], zs=1, label='Train Loss', color='red', linewidth=2)\n",
    "    ax2.plot(epochs, history_model_v3.history['val_loss'], zs=2, label='Validation Loss', color='purple', linewidth=2)\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_zlabel(\"Type\")\n",
    "    ax2.set_title(\"Training and Validation Loss in 3D\")\n",
    "    ax2.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning_3d(history_model_v3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCEPTION v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:14:10.942610Z",
     "iopub.status.busy": "2025-01-30T12:14:10.942270Z",
     "iopub.status.idle": "2025-01-30T12:14:10.946669Z",
     "shell.execute_reply": "2025-01-30T12:14:10.945597Z",
     "shell.execute_reply.started": "2025-01-30T12:14:10.942584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# defining some parameters for the loader\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 120\n",
    "img_width = 120\n",
    "\n",
    "# lower resolution images reduce the definition/clarity of certain features in images.\n",
    "# It can make it harder for CNN to learn the features required for classification or detection.\n",
    "# working with 120 x 120 resolution images for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:39:03.796283Z",
     "iopub.status.busy": "2025-01-30T12:39:03.795989Z",
     "iopub.status.idle": "2025-01-30T12:39:04.908193Z",
     "shell.execute_reply": "2025-01-30T12:39:04.907489Z",
     "shell.execute_reply.started": "2025-01-30T12:39:03.796261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Lambda, GlobalAveragePooling2D, Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import InceptionV4\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a more complex InceptionV4-based model\n",
    "def create_improved_inception_model(input_shape=(120, 120, 3), num_classes=3):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # Resize to InceptionV4 input size (299x299)\n",
    "    x = Lambda(lambda image: tf.image.resize(image, (299, 299)), output_shape=(299, 299, 3))(input_tensor)\n",
    "\n",
    "    # Load InceptionV3 without top layers\n",
    "    base_model = InceptionV4(weights=None, include_top=False, input_tensor=x)\n",
    "\n",
    "    # Unfreeze more layers of the base model (not just the last few)\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = True  # Unfreeze all layers\n",
    "\n",
    "    # Add additional layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Convert features into a single vector\n",
    "    x = Dense(512, activation='relu')(x)  # Add a Dense layer with 512 units\n",
    "    x = BatchNormalization()(x)  # Normalize the activations\n",
    "    x = Dropout(0.5)(x)  # Add Dropout to reduce overfitting\n",
    "    x = Dense(256, activation='relu')(x)  # Add another Dense layer with 256 units\n",
    "    x = BatchNormalization()(x)  # Normalize again\n",
    "    x = Dropout(0.5)(x)  # Another Dropout layer\n",
    "\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Final classification layer\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    return model\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 3\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_improved_inception_model(input_shape=(120, 120, 3), num_classes=num_classes)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()  # Optional: Check the model structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:39:08.500580Z",
     "iopub.status.busy": "2025-01-30T12:39:08.500260Z",
     "iopub.status.idle": "2025-01-30T12:39:08.504842Z",
     "shell.execute_reply": "2025-01-30T12:39:08.504087Z",
     "shell.execute_reply.started": "2025-01-30T12:39:08.500553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.2,           # Reduce learning rate by half\n",
    "    patience=5,           # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-5,          # Minimum learning rate allowed\n",
    "    verbose=1             # Print a message when the learning rate is reduced\n",
    ")\n",
    "callbacks = [lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:39:10.007718Z",
     "iopub.status.busy": "2025-01-30T12:39:10.007387Z",
     "iopub.status.idle": "2025-01-30T12:39:10.011544Z",
     "shell.execute_reply": "2025-01-30T12:39:10.010618Z",
     "shell.execute_reply.started": "2025-01-30T12:39:10.007691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable graph optimization\n",
    "tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:39:10.323091Z",
     "iopub.status.busy": "2025-01-30T12:39:10.322803Z",
     "iopub.status.idle": "2025-01-30T12:39:10.328974Z",
     "shell.execute_reply": "2025-01-30T12:39:10.328288Z",
     "shell.execute_reply.started": "2025-01-30T12:39:10.323068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:39:13.240200Z",
     "iopub.status.busy": "2025-01-30T12:39:13.239916Z",
     "iopub.status.idle": "2025-01-30T12:39:13.249072Z",
     "shell.execute_reply": "2025-01-30T12:39:13.248341Z",
     "shell.execute_reply.started": "2025-01-30T12:39:13.240177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:39:13.536033Z",
     "iopub.status.busy": "2025-01-30T12:39:13.535746Z",
     "iopub.status.idle": "2025-01-30T12:39:13.539993Z",
     "shell.execute_reply": "2025-01-30T12:39:13.539081Z",
     "shell.execute_reply.started": "2025-01-30T12:39:13.536011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set GPU memory growth to avoid memory fragmentation issues\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:39:30.437654Z",
     "iopub.status.busy": "2025-01-30T12:39:30.437288Z",
     "iopub.status.idle": "2025-01-30T13:26:15.145825Z",
     "shell.execute_reply": "2025-01-30T13:26:15.144930Z",
     "shell.execute_reply.started": "2025-01-30T12:39:30.437623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"GPU is available\")\n",
    "    # Set memory growth for GPU\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize Adam optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# Specify loss function\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "history_model_v4 = model.fit(\n",
    "                    train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    #steps_per_epoch=100,\n",
    "                    epochs=epochs,\n",
    "                   # callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:15.147313Z",
     "iopub.status.busy": "2025-01-30T13:26:15.147075Z",
     "iopub.status.idle": "2025-01-30T13:26:15.606036Z",
     "shell.execute_reply": "2025-01-30T13:26:15.605276Z",
     "shell.execute_reply.started": "2025-01-30T13:26:15.147291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning(history_model_v4):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss with different colors.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_model_v4.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history_model_v4.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_model_v4.history['loss'], label='Train Loss', color='red')\n",
    "    plt.plot(history_model_v4.history['val_loss'], label='Validation Loss', color='purple')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning(history_model_v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:15.607896Z",
     "iopub.status.busy": "2025-01-30T13:26:15.607666Z",
     "iopub.status.idle": "2025-01-30T13:26:15.613579Z",
     "shell.execute_reply": "2025-01-30T13:26:15.612767Z",
     "shell.execute_reply.started": "2025-01-30T13:26:15.607875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:15.614866Z",
     "iopub.status.busy": "2025-01-30T13:26:15.614681Z",
     "iopub.status.idle": "2025-01-30T13:26:32.683720Z",
     "shell.execute_reply": "2025-01-30T13:26:32.682985Z",
     "shell.execute_reply.started": "2025-01-30T13:26:15.614848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluating performance on test set\n",
    "\n",
    "results = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss of the model  is - test \", results[0])\n",
    "print(\"Accuracy of the model is - test\", results[1]*100, \"%\\n\")\n",
    "\n",
    "\n",
    "results = model.evaluate(val_ds)\n",
    "\n",
    "print(\"Loss of the model  is - val \", results[0])\n",
    "print(\"Accuracy of the model is - val\", results[1]*100, \"%\\n\")\n",
    "\n",
    "results = model.evaluate(train_ds)\n",
    "\n",
    "print(\"Loss of the model  is - train \", results[0])\n",
    "print(\"Accuracy of the model is - train\", results[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:32.684872Z",
     "iopub.status.busy": "2025-01-30T13:26:32.684554Z",
     "iopub.status.idle": "2025-01-30T13:26:45.016705Z",
     "shell.execute_reply": "2025-01-30T13:26:45.015956Z",
     "shell.execute_reply.started": "2025-01-30T13:26:32.684837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = np.array([])\n",
    "labels =  np.array([])\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x, verbose=0),axis=1)\n",
    "    predictions = np.concatenate([predictions, y_pred])\n",
    "    labels = np.concatenate([labels, y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:45.017835Z",
     "iopub.status.busy": "2025-01-30T13:26:45.017598Z",
     "iopub.status.idle": "2025-01-30T13:26:45.031899Z",
     "shell.execute_reply": "2025-01-30T13:26:45.031053Z",
     "shell.execute_reply.started": "2025-01-30T13:26:45.017815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(labels,predictions,\n",
    "                           target_names = ['china fan dance', 'Sword Dance', 'dragon dance images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:45.033100Z",
     "iopub.status.busy": "2025-01-30T13:26:45.032839Z",
     "iopub.status.idle": "2025-01-30T13:26:52.588163Z",
     "shell.execute_reply": "2025-01-30T13:26:52.587212Z",
     "shell.execute_reply.started": "2025-01-30T13:26:45.033070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Replace with actual class names)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of rows and columns for the grid\n",
    "rows, cols = 4, 4  \n",
    "\n",
    "# Take a batch of images and labels from the dataset\n",
    "for images, labels in test_ds.take(1):  # Take only one batch\n",
    "    plt.figure(figsize=(12, 12))  # Set figure size\n",
    "\n",
    "    for i in range(min(rows * cols, len(images))):  # Ensure it doesn't exceed dataset size\n",
    "        plt.subplot(rows, cols, i + 1)  # Create a 4-row, 4-column subplot\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert image to uint8 format\n",
    "        plt.axis(\"off\")  # Hide axes\n",
    "\n",
    "        # Get model predictions\n",
    "        predictions = model.predict(images[i][None, ...])  # Get prediction probabilities\n",
    "        predicted_class = np.argmax(predictions)  # Get class index\n",
    "        confidence = np.max(predictions) * 100  # Get confidence in percentage\n",
    "\n",
    "        # Set title with class name and confidence\n",
    "        plt.title(f\"{class_names[predicted_class]}\\n{confidence:.2f}%\", fontsize=10, color=\"red\")\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()  # Display the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:52.590674Z",
     "iopub.status.busy": "2025-01-30T13:26:52.590364Z",
     "iopub.status.idle": "2025-01-30T13:26:52.594133Z",
     "shell.execute_reply": "2025-01-30T13:26:52.593367Z",
     "shell.execute_reply.started": "2025-01-30T13:26:52.590645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:52.595459Z",
     "iopub.status.busy": "2025-01-30T13:26:52.595212Z",
     "iopub.status.idle": "2025-01-30T13:26:54.239067Z",
     "shell.execute_reply": "2025-01-30T13:26:54.238370Z",
     "shell.execute_reply.started": "2025-01-30T13:26:52.595431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize empty lists for true labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through the test dataset to obtain predictions\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x), axis=1)\n",
    "    true_labels.extend(y.numpy())\n",
    "    predicted_labels.extend(y_pred)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "#print(classification_report(true_labels, predicted_labels,\n",
    "#                            target_names=[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:54.239985Z",
     "iopub.status.busy": "2025-01-30T13:26:54.239786Z",
     "iopub.status.idle": "2025-01-30T13:26:54.519977Z",
     "shell.execute_reply": "2025-01-30T13:26:54.519099Z",
     "shell.execute_reply.started": "2025-01-30T13:26:54.239966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix (cm):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        cmap = 'Blues', \n",
    "        linecolor = 'black', \n",
    "        linewidth = 1, \n",
    "        annot = True, \n",
    "        fmt = '', \n",
    "        xticklabels = class_names, \n",
    "        yticklabels = class_names)\n",
    "    \n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:54.521280Z",
     "iopub.status.busy": "2025-01-30T13:26:54.520960Z",
     "iopub.status.idle": "2025-01-30T13:26:54.705962Z",
     "shell.execute_reply": "2025-01-30T13:26:54.705076Z",
     "shell.execute_reply.started": "2025-01-30T13:26:54.521246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix_3d(cm, class_names):\n",
    "    \"\"\"\n",
    "    Plots a 3D surface plot for the confusion matrix.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create the X and Y grid for the confusion matrix\n",
    "    x, y = np.meshgrid(np.arange(cm.shape[0]), np.arange(cm.shape[1]))\n",
    "\n",
    "    # Plotting the surface\n",
    "    ax.plot_surface(x, y, cm, cmap='Blues', edgecolor='black', linewidth=1)\n",
    "\n",
    "    # Annotate the surface with text (values from the confusion matrix)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(x[i, j], y[i, j], cm[i, j], str(cm[i, j]), color='black', fontsize=12, ha='center')\n",
    "\n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_zlabel('Count')\n",
    "\n",
    "    # Set ticks for X and Y axes based on class names\n",
    "    ax.set_xticks(np.arange(cm.shape[1]))\n",
    "    ax.set_yticks(np.arange(cm.shape[0]))\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title('Confusion Matrix in 3D')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "#[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]\n",
    "# Example usage:\n",
    "# Assuming you have a confusion matrix `cm` and class names in `class_names`\n",
    "class_names = ['china fan dance', 'Sword Dance', 'dragon dance images']  # Modify with your actual class names\n",
    "plot_confusion_matrix_3d(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:26:54.707299Z",
     "iopub.status.busy": "2025-01-30T13:26:54.706936Z",
     "iopub.status.idle": "2025-01-30T13:26:55.209853Z",
     "shell.execute_reply": "2025-01-30T13:26:55.208873Z",
     "shell.execute_reply.started": "2025-01-30T13:26:54.707262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Modify based on your dataset)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of epochs for plotting (replace with actual epoch count)\n",
    "epochs = np.arange(1, 11)  # Example: 10 epochs\n",
    "\n",
    "# Create a larger plot\n",
    "fig, ax = plt.subplots(figsize=(16, 12))  # Enlarged plot size\n",
    "\n",
    "# Set labels for axes and title\n",
    "ax.set_xlabel('Epochs', fontsize=14, weight='bold')\n",
    "ax.set_ylabel('Confidence (%)', fontsize=14, weight='bold')\n",
    "ax.set_title('Model Accuracy with Confidence Bubbles', fontsize=16, weight='bold')\n",
    "\n",
    "# Variables to store bubble data\n",
    "x_data = []\n",
    "y_data = []\n",
    "sizes = []  # Bubble sizes (confidence or any other measure)\n",
    "colors = []  # Bubble colors (can represent confidence)\n",
    "\n",
    "# Generate random data for demonstration\n",
    "# Replace this section with real model predictions for each epoch\n",
    "for epoch in epochs:\n",
    "    for class_idx in range(len(class_names)):\n",
    "        # Simulating confidence for each class in each epoch\n",
    "        confidence = np.random.uniform(0.60, 1.00) * 100  # Random confidence between 60 and 100%\n",
    "        \n",
    "        # Store the data for plotting\n",
    "        x_data.append(epoch)\n",
    "        y_data.append(confidence)\n",
    "        sizes.append(confidence * 25)  # Increased bubble size (scaled more)\n",
    "        colors.append(confidence)  # Set color based on confidence\n",
    "\n",
    "# Scatter plot with bubbles\n",
    "scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='plasma', alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Add color bar for confidence\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='Confidence %')\n",
    "cbar.set_ticks([0, 25, 50, 75, 100])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Adjust spacing for labels to avoid overlap and keep labels inside the plot\n",
    "for i in range(len(x_data)):\n",
    "    # Offset y-position to avoid going outside the plotting area\n",
    "    label_x = x_data[i]\n",
    "    label_y = y_data[i] + 5  # Adjust this offset if necessary\n",
    "\n",
    "    # Check if the label is too close to the top or bottom and adjust\n",
    "    if label_y > 100:  # If label goes above the upper limit\n",
    "        label_y = 95  # Place label a little below 100\n",
    "    elif label_y < 10:  # If label is too close to the bottom\n",
    "        label_y = 15  # Place label a little above 0\n",
    "    \n",
    "    ax.text(label_x, label_y, f'{class_names[x_data[i] % len(class_names)]}\\n{y_data[i]:.1f}%', \n",
    "            ha='center', fontsize=8, color='black', weight='bold', fontstyle='italic', \n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))  # Background for better readability\n",
    "\n",
    "# Adjusting grid for better presentation\n",
    "ax.set_xticks(epochs)\n",
    "ax.set_yticks(np.arange(0, 110, 10))\n",
    "ax.set_yticklabels(np.arange(0, 110, 10), fontsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Increase space between labels and bubbles\n",
    "ax.margins(x=0.05, y=0.1)\n",
    "\n",
    "# Tight layout to prevent overlap\n",
    "plt.tight_layout(pad=5.0)  # Increased padding for better spacing\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:38:55.093110Z",
     "iopub.status.busy": "2025-01-30T13:38:55.092831Z",
     "iopub.status.idle": "2025-01-30T13:38:56.443529Z",
     "shell.execute_reply": "2025-01-30T13:38:56.442650Z",
     "shell.execute_reply.started": "2025-01-30T13:38:55.093091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles(history_model_v4):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v4.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v4.history['accuracy'],\n",
    "        'val': history_model_v4.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 2D plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for start, end in epoch_ranges:\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with Bubbles')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles(history_model_v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:36:35.233338Z",
     "iopub.status.busy": "2025-01-30T13:36:35.233052Z",
     "iopub.status.idle": "2025-01-30T13:36:36.796233Z",
     "shell.execute_reply": "2025-01-30T13:36:36.795313Z",
     "shell.execute_reply.started": "2025-01-30T13:36:35.233314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles_separated(history_model_v4):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v4.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v4.history['accuracy'],\n",
    "        'val': history_model_v4.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Variables to store bubble data\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        sizes = []  # Bubble sizes (based on accuracy)\n",
    "        colors = []  # Bubble colors (for visualization)\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "        # Scatter plot with bubbles\n",
    "        scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add color bar for accuracy\n",
    "        plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles_separated(history_model_v4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:36:46.185703Z",
     "iopub.status.busy": "2025-01-30T13:36:46.185337Z",
     "iopub.status.idle": "2025-01-30T13:36:47.356771Z",
     "shell.execute_reply": "2025-01-30T13:36:47.355847Z",
     "shell.execute_reply.started": "2025-01-30T13:36:46.185673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_solid_lines(history_model_v4):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100),\n",
    "    using solid lines to represent the accuracies.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v4.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v4.history['accuracy'],\n",
    "        'val': history_model_v4.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Plot the lines for training and validation accuracy with new colors\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Training Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='darkorange', linewidth=3)\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='mediumseagreen', linewidth=3)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_solid_lines(history_model_v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:36:51.863278Z",
     "iopub.status.busy": "2025-01-30T13:36:51.862997Z",
     "iopub.status.idle": "2025-01-30T13:36:52.234698Z",
     "shell.execute_reply": "2025-01-30T13:36:52.233795Z",
     "shell.execute_reply.started": "2025-01-30T13:36:51.863255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def plot_accuracy_with_3d_lines(history_model_v4):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate 3D subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    Adds enhancements such as color gradients for a stunning 3D effect.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v4.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v4.history['accuracy'],\n",
    "        'val': history_model_v4.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a figure for the 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')  # 3D subplot\n",
    "    \n",
    "    # Set the colormap and normalize the values for color gradients\n",
    "    cmap = cm.viridis  # You can change this to any other colormap such as 'plasma', 'inferno', etc.\n",
    "    norm = Normalize(vmin=1, vmax=100)\n",
    "\n",
    "    # Loop through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Color gradient based on epoch number\n",
    "        train_colors = cmap(norm(epoch_range))  # Apply colormap to training accuracy\n",
    "        val_colors = cmap(norm(epoch_range))    # Apply colormap to validation accuracy\n",
    "\n",
    "        # 3D plot for training accuracy\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=1, label=f'Training Accuracy (Epochs {start}-{end})', marker='o', color=train_colors[-1], linewidth=3, markersize=8)\n",
    "        \n",
    "        # 3D plot for validation accuracy\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=2, label=f'Validation Accuracy (Epochs {start}-{end})', marker='^', color=val_colors[-1], linewidth=3, markersize=8)\n",
    "\n",
    "    # Set labels with improved styling\n",
    "    ax.set_xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.set_zlabel('Accuracy Level', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Set title with improved styling\n",
    "    ax.set_title('Training and Validation Accuracy in 3D', fontsize=16, fontweight='bold', color='darkblue')\n",
    "\n",
    "    # Customize the grid and background for better aesthetics\n",
    "    ax.grid(True, color='gray', linestyle='--', linewidth=0.5)\n",
    "    ax.set_facecolor('whitesmoke')\n",
    "    \n",
    "    # Adjust the view angle for better clarity\n",
    "    ax.view_init(30, 45)\n",
    "\n",
    "    # Add a legend with better positioning\n",
    "    ax.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_lines(history_model_v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:36:59.902835Z",
     "iopub.status.busy": "2025-01-30T13:36:59.902500Z",
     "iopub.status.idle": "2025-01-30T13:37:00.325976Z",
     "shell.execute_reply": "2025-01-30T13:37:00.325099Z",
     "shell.execute_reply.started": "2025-01-30T13:36:59.902806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_accuracy_with_3d_bubbles(history_model_v4):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with 3D bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v4.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_v4.history['accuracy'],\n",
    "        'val': history_model_v4.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_zlabel('Accuracy Level')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    z_data = []  # Z-axis for different epoch ranges\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            z_data.append(idx + 1)  # Different z values based on epoch range (1, 2, 3, 4)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles (for train and validation accuracy)\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=idx + 1, label=f'Train Accuracy (Epochs {start}-{end})', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=idx + 1, label=f'Validation Accuracy (Epochs {start}-{end})', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, z_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with 3D Bubbles', fontsize=16, fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_bubbles(history_model_v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:37:04.889163Z",
     "iopub.status.busy": "2025-01-30T13:37:04.888854Z",
     "iopub.status.idle": "2025-01-30T13:37:05.270356Z",
     "shell.execute_reply": "2025-01-30T13:37:05.269523Z",
     "shell.execute_reply.started": "2025-01-30T13:37:04.889135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_learning_3d(history_model_v4):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss in 3D.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_v4.history['accuracy']) + 1)\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # First 3D subplot for accuracy\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.plot(epochs, history_model_v4.history['accuracy'], zs=1, label='Train Accuracy', color='blue', linewidth=2)\n",
    "    ax1.plot(epochs, history_model_v4.history['val_accuracy'], zs=2, label='Validation Accuracy', color='green', linewidth=2)\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_zlabel(\"Type\")\n",
    "    ax1.set_title(\"Training and Validation Accuracy in 3D\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Second 3D subplot for loss\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.plot(epochs, history_model_v4.history['loss'], zs=1, label='Train Loss', color='red', linewidth=2)\n",
    "    ax2.plot(epochs, history_model_v4.history['val_loss'], zs=2, label='Validation Loss', color='purple', linewidth=2)\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_zlabel(\"Type\")\n",
    "    ax2.set_title(\"Training and Validation Loss in 3D\")\n",
    "    ax2.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning_3d(history_model_v4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:13.685552Z",
     "iopub.status.busy": "2025-01-30T13:39:13.685200Z",
     "iopub.status.idle": "2025-01-30T13:39:13.689123Z",
     "shell.execute_reply": "2025-01-30T13:39:13.688460Z",
     "shell.execute_reply.started": "2025-01-30T13:39:13.685522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# defining some parameters for the loader\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 120\n",
    "img_width = 120\n",
    "\n",
    "# lower resolution images reduce the definition/clarity of certain features in images.\n",
    "# It can make it harder for CNN to learn the features required for classification or detection.\n",
    "# working with 120 x 120 resolution images for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:17.439223Z",
     "iopub.status.busy": "2025-01-30T13:39:17.438875Z",
     "iopub.status.idle": "2025-01-30T13:39:18.344606Z",
     "shell.execute_reply": "2025-01-30T13:39:18.343750Z",
     "shell.execute_reply.started": "2025-01-30T13:39:17.439195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 3\n",
    "\n",
    "# Define input dimensions (adjust according to your data)\n",
    "img_height, img_width = 120, 120  # Example dimensions\n",
    "\n",
    "# Load ResNet50 base model without top layers\n",
    "resnet_base = ResNet50(weights=None, include_top=False)\n",
    "\n",
    "# Define input tensor with specific shape\n",
    "input_tensor = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add ResNet50 base model\n",
    "x = resnet_base(input_tensor)\n",
    "\n",
    "# Add GlobalAveragePooling2D layer to reduce spatial dimensions\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add Dense layers with BatchNormalization and Dropout for regularization\n",
    "x = Dense(1024, activation='relu')(x)  # Increased units for more capacity\n",
    "x = BatchNormalization()(x)  # BatchNormalization to stabilize training\n",
    "x = Dropout(0.3)(x)  # Higher dropout to reduce overfitting\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # BatchNormalization\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # BatchNormalization\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Optional: Add more layers for additional capacity\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # BatchNormalization\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Output layer\n",
    "output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:24.065285Z",
     "iopub.status.busy": "2025-01-30T13:39:24.064938Z",
     "iopub.status.idle": "2025-01-30T13:39:24.069248Z",
     "shell.execute_reply": "2025-01-30T13:39:24.068497Z",
     "shell.execute_reply.started": "2025-01-30T13:39:24.065256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.2,           # Reduce learning rate by half\n",
    "    patience=5,           # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-5,          # Minimum learning rate allowed\n",
    "    verbose=1             # Print a message when the learning rate is reduced\n",
    ")\n",
    "callbacks = [lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:26.348223Z",
     "iopub.status.busy": "2025-01-30T13:39:26.347941Z",
     "iopub.status.idle": "2025-01-30T13:39:26.352242Z",
     "shell.execute_reply": "2025-01-30T13:39:26.351341Z",
     "shell.execute_reply.started": "2025-01-30T13:39:26.348200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable graph optimization\n",
    "tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:29.043947Z",
     "iopub.status.busy": "2025-01-30T13:39:29.043608Z",
     "iopub.status.idle": "2025-01-30T13:39:29.049964Z",
     "shell.execute_reply": "2025-01-30T13:39:29.049247Z",
     "shell.execute_reply.started": "2025-01-30T13:39:29.043914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:31.018229Z",
     "iopub.status.busy": "2025-01-30T13:39:31.017946Z",
     "iopub.status.idle": "2025-01-30T13:39:31.026306Z",
     "shell.execute_reply": "2025-01-30T13:39:31.025597Z",
     "shell.execute_reply.started": "2025-01-30T13:39:31.018207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:33.281113Z",
     "iopub.status.busy": "2025-01-30T13:39:33.280840Z",
     "iopub.status.idle": "2025-01-30T13:39:33.285311Z",
     "shell.execute_reply": "2025-01-30T13:39:33.284450Z",
     "shell.execute_reply.started": "2025-01-30T13:39:33.281092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set GPU memory growth to avoid memory fragmentation issues\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T13:39:52.235872Z",
     "iopub.status.busy": "2025-01-30T13:39:52.235581Z",
     "iopub.status.idle": "2025-01-30T14:16:54.627444Z",
     "shell.execute_reply": "2025-01-30T14:16:54.626750Z",
     "shell.execute_reply.started": "2025-01-30T13:39:52.235850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"GPU is available\")\n",
    "    # Set memory growth for GPU\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize Adam optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# Specify loss function\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "history_model_net = model.fit(\n",
    "                    train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    #steps_per_epoch=100,\n",
    "                    epochs=epochs,\n",
    "                   # callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:16:54.628846Z",
     "iopub.status.busy": "2025-01-30T14:16:54.628617Z",
     "iopub.status.idle": "2025-01-30T14:16:55.142531Z",
     "shell.execute_reply": "2025-01-30T14:16:55.141705Z",
     "shell.execute_reply.started": "2025-01-30T14:16:54.628826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss with different colors.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_model_net.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history_model_net.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_model_net.history['loss'], label='Train Loss', color='red')\n",
    "    plt.plot(history_model_net.history['val_loss'], label='Validation Loss', color='purple')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:16:55.144202Z",
     "iopub.status.busy": "2025-01-30T14:16:55.143845Z",
     "iopub.status.idle": "2025-01-30T14:16:55.149815Z",
     "shell.execute_reply": "2025-01-30T14:16:55.148920Z",
     "shell.execute_reply.started": "2025-01-30T14:16:55.144175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:14.073791Z",
     "iopub.status.busy": "2025-01-30T14:17:14.073382Z",
     "iopub.status.idle": "2025-01-30T14:17:21.049467Z",
     "shell.execute_reply": "2025-01-30T14:17:21.048750Z",
     "shell.execute_reply.started": "2025-01-30T14:17:14.073760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluating performance on test set\n",
    "\n",
    "results = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss of the model  is - test \", results[0])\n",
    "print(\"Accuracy of the model is - test\", results[1]*100, \"%\\n\")\n",
    "\n",
    "\n",
    "results = model.evaluate(val_ds)\n",
    "\n",
    "print(\"Loss of the model  is - val \", results[0])\n",
    "print(\"Accuracy of the model is - val\", results[1]*100, \"%\\n\")\n",
    "\n",
    "results = model.evaluate(train_ds)\n",
    "\n",
    "print(\"Loss of the model  is - train \", results[0])\n",
    "print(\"Accuracy of the model is - train\", results[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:16:55.151171Z",
     "iopub.status.busy": "2025-01-30T14:16:55.150880Z",
     "iopub.status.idle": "2025-01-30T14:17:01.835665Z",
     "shell.execute_reply": "2025-01-30T14:17:01.834779Z",
     "shell.execute_reply.started": "2025-01-30T14:16:55.151149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = np.array([])\n",
    "labels =  np.array([])\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x, verbose=0),axis=1)\n",
    "    predictions = np.concatenate([predictions, y_pred])\n",
    "    labels = np.concatenate([labels, y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:01.836978Z",
     "iopub.status.busy": "2025-01-30T14:17:01.836682Z",
     "iopub.status.idle": "2025-01-30T14:17:01.849942Z",
     "shell.execute_reply": "2025-01-30T14:17:01.849239Z",
     "shell.execute_reply.started": "2025-01-30T14:17:01.836954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(labels,predictions,\n",
    "                           target_names = ['china fan dance', 'Sword Dance', 'dragon dance images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:01.850938Z",
     "iopub.status.busy": "2025-01-30T14:17:01.850745Z",
     "iopub.status.idle": "2025-01-30T14:17:06.566085Z",
     "shell.execute_reply": "2025-01-30T14:17:06.565240Z",
     "shell.execute_reply.started": "2025-01-30T14:17:01.850917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Replace with actual class names)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of rows and columns for the grid\n",
    "rows, cols = 4, 4  \n",
    "\n",
    "# Take a batch of images and labels from the dataset\n",
    "for images, labels in test_ds.take(1):  # Take only one batch\n",
    "    plt.figure(figsize=(12, 12))  # Set figure size\n",
    "\n",
    "    for i in range(min(rows * cols, len(images))):  # Ensure it doesn't exceed dataset size\n",
    "        plt.subplot(rows, cols, i + 1)  # Create a 4-row, 4-column subplot\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert image to uint8 format\n",
    "        plt.axis(\"off\")  # Hide axes\n",
    "\n",
    "        # Get model predictions\n",
    "        predictions = model.predict(images[i][None, ...])  # Get prediction probabilities\n",
    "        predicted_class = np.argmax(predictions)  # Get class index\n",
    "        confidence = np.max(predictions) * 100  # Get confidence in percentage\n",
    "\n",
    "        # Set title with class name and confidence\n",
    "        plt.title(f\"{class_names[predicted_class]}\\n{confidence:.2f}%\", fontsize=10, color=\"red\")\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()  # Display the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:06.567452Z",
     "iopub.status.busy": "2025-01-30T14:17:06.567090Z",
     "iopub.status.idle": "2025-01-30T14:17:06.571703Z",
     "shell.execute_reply": "2025-01-30T14:17:06.570897Z",
     "shell.execute_reply.started": "2025-01-30T14:17:06.567387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:06.573870Z",
     "iopub.status.busy": "2025-01-30T14:17:06.573651Z",
     "iopub.status.idle": "2025-01-30T14:17:07.652961Z",
     "shell.execute_reply": "2025-01-30T14:17:07.652251Z",
     "shell.execute_reply.started": "2025-01-30T14:17:06.573850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize empty lists for true labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through the test dataset to obtain predictions\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x), axis=1)\n",
    "    true_labels.extend(y.numpy())\n",
    "    predicted_labels.extend(y_pred)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "#print(classification_report(true_labels, predicted_labels,\n",
    "#                            target_names=[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:07.654267Z",
     "iopub.status.busy": "2025-01-30T14:17:07.654024Z",
     "iopub.status.idle": "2025-01-30T14:17:07.929705Z",
     "shell.execute_reply": "2025-01-30T14:17:07.928819Z",
     "shell.execute_reply.started": "2025-01-30T14:17:07.654246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix (cm):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        cmap = 'Blues', \n",
    "        linecolor = 'black', \n",
    "        linewidth = 1, \n",
    "        annot = True, \n",
    "        fmt = '', \n",
    "        xticklabels = class_names, \n",
    "        yticklabels = class_names)\n",
    "    \n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:07.930908Z",
     "iopub.status.busy": "2025-01-30T14:17:07.930634Z",
     "iopub.status.idle": "2025-01-30T14:17:08.121847Z",
     "shell.execute_reply": "2025-01-30T14:17:08.121001Z",
     "shell.execute_reply.started": "2025-01-30T14:17:07.930882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix_3d(cm, class_names):\n",
    "    \"\"\"\n",
    "    Plots a 3D surface plot for the confusion matrix.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create the X and Y grid for the confusion matrix\n",
    "    x, y = np.meshgrid(np.arange(cm.shape[0]), np.arange(cm.shape[1]))\n",
    "\n",
    "    # Plotting the surface\n",
    "    ax.plot_surface(x, y, cm, cmap='Blues', edgecolor='black', linewidth=1)\n",
    "\n",
    "    # Annotate the surface with text (values from the confusion matrix)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(x[i, j], y[i, j], cm[i, j], str(cm[i, j]), color='black', fontsize=12, ha='center')\n",
    "\n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_zlabel('Count')\n",
    "\n",
    "    # Set ticks for X and Y axes based on class names\n",
    "    ax.set_xticks(np.arange(cm.shape[1]))\n",
    "    ax.set_yticks(np.arange(cm.shape[0]))\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title('Confusion Matrix in 3D')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "#[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]\n",
    "# Example usage:\n",
    "# Assuming you have a confusion matrix `cm` and class names in `class_names`\n",
    "class_names = ['china fan dance', 'Sword Dance', 'dragon dance images']  # Modify with your actual class names\n",
    "plot_confusion_matrix_3d(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:08.123169Z",
     "iopub.status.busy": "2025-01-30T14:17:08.122784Z",
     "iopub.status.idle": "2025-01-30T14:17:08.622703Z",
     "shell.execute_reply": "2025-01-30T14:17:08.621781Z",
     "shell.execute_reply.started": "2025-01-30T14:17:08.123137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Modify based on your dataset)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of epochs for plotting (replace with actual epoch count)\n",
    "epochs = np.arange(1, 11)  # Example: 10 epochs\n",
    "\n",
    "# Create a larger plot\n",
    "fig, ax = plt.subplots(figsize=(16, 12))  # Enlarged plot size\n",
    "\n",
    "# Set labels for axes and title\n",
    "ax.set_xlabel('Epochs', fontsize=14, weight='bold')\n",
    "ax.set_ylabel('Confidence (%)', fontsize=14, weight='bold')\n",
    "ax.set_title('Model Accuracy with Confidence Bubbles', fontsize=16, weight='bold')\n",
    "\n",
    "# Variables to store bubble data\n",
    "x_data = []\n",
    "y_data = []\n",
    "sizes = []  # Bubble sizes (confidence or any other measure)\n",
    "colors = []  # Bubble colors (can represent confidence)\n",
    "\n",
    "# Generate random data for demonstration\n",
    "# Replace this section with real model predictions for each epoch\n",
    "for epoch in epochs:\n",
    "    for class_idx in range(len(class_names)):\n",
    "        # Simulating confidence for each class in each epoch\n",
    "        confidence = np.random.uniform(0.60, 1.00) * 100  # Random confidence between 60 and 100%\n",
    "        \n",
    "        # Store the data for plotting\n",
    "        x_data.append(epoch)\n",
    "        y_data.append(confidence)\n",
    "        sizes.append(confidence * 25)  # Increased bubble size (scaled more)\n",
    "        colors.append(confidence)  # Set color based on confidence\n",
    "\n",
    "# Scatter plot with bubbles\n",
    "scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='plasma', alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Add color bar for confidence\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='Confidence %')\n",
    "cbar.set_ticks([0, 25, 50, 75, 100])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Adjust spacing for labels to avoid overlap and keep labels inside the plot\n",
    "for i in range(len(x_data)):\n",
    "    # Offset y-position to avoid going outside the plotting area\n",
    "    label_x = x_data[i]\n",
    "    label_y = y_data[i] + 5  # Adjust this offset if necessary\n",
    "\n",
    "    # Check if the label is too close to the top or bottom and adjust\n",
    "    if label_y > 100:  # If label goes above the upper limit\n",
    "        label_y = 95  # Place label a little below 100\n",
    "    elif label_y < 10:  # If label is too close to the bottom\n",
    "        label_y = 15  # Place label a little above 0\n",
    "    \n",
    "    ax.text(label_x, label_y, f'{class_names[x_data[i] % len(class_names)]}\\n{y_data[i]:.1f}%', \n",
    "            ha='center', fontsize=8, color='black', weight='bold', fontstyle='italic', \n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))  # Background for better readability\n",
    "\n",
    "# Adjusting grid for better presentation\n",
    "ax.set_xticks(epochs)\n",
    "ax.set_yticks(np.arange(0, 110, 10))\n",
    "ax.set_yticklabels(np.arange(0, 110, 10), fontsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Increase space between labels and bubbles\n",
    "ax.margins(x=0.05, y=0.1)\n",
    "\n",
    "# Tight layout to prevent overlap\n",
    "plt.tight_layout(pad=5.0)  # Increased padding for better spacing\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:08.623870Z",
     "iopub.status.busy": "2025-01-30T14:17:08.623575Z",
     "iopub.status.idle": "2025-01-30T14:17:09.047772Z",
     "shell.execute_reply": "2025-01-30T14:17:09.046986Z",
     "shell.execute_reply.started": "2025-01-30T14:17:08.623843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 2D plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for start, end in epoch_ranges:\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with Bubbles')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:09.048746Z",
     "iopub.status.busy": "2025-01-30T14:17:09.048519Z",
     "iopub.status.idle": "2025-01-30T14:17:11.755800Z",
     "shell.execute_reply": "2025-01-30T14:17:11.754871Z",
     "shell.execute_reply.started": "2025-01-30T14:17:09.048726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles_separated(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Variables to store bubble data\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        sizes = []  # Bubble sizes (based on accuracy)\n",
    "        colors = []  # Bubble colors (for visualization)\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "        # Scatter plot with bubbles\n",
    "        scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add color bar for accuracy\n",
    "        plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles_separated(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:11.756884Z",
     "iopub.status.busy": "2025-01-30T14:17:11.756667Z",
     "iopub.status.idle": "2025-01-30T14:17:12.908936Z",
     "shell.execute_reply": "2025-01-30T14:17:12.907993Z",
     "shell.execute_reply.started": "2025-01-30T14:17:11.756865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_solid_lines(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100),\n",
    "    using solid lines to represent the accuracies.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Plot the lines for training and validation accuracy with new colors\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Training Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='darkorange', linewidth=3)\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='mediumseagreen', linewidth=3)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_solid_lines(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:12.909860Z",
     "iopub.status.busy": "2025-01-30T14:17:12.909649Z",
     "iopub.status.idle": "2025-01-30T14:17:13.281051Z",
     "shell.execute_reply": "2025-01-30T14:17:13.280042Z",
     "shell.execute_reply.started": "2025-01-30T14:17:12.909840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def plot_accuracy_with_3d_lines(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate 3D subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    Adds enhancements such as color gradients for a stunning 3D effect.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a figure for the 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')  # 3D subplot\n",
    "    \n",
    "    # Set the colormap and normalize the values for color gradients\n",
    "    cmap = cm.viridis  # You can change this to any other colormap such as 'plasma', 'inferno', etc.\n",
    "    norm = Normalize(vmin=1, vmax=100)\n",
    "\n",
    "    # Loop through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Color gradient based on epoch number\n",
    "        train_colors = cmap(norm(epoch_range))  # Apply colormap to training accuracy\n",
    "        val_colors = cmap(norm(epoch_range))    # Apply colormap to validation accuracy\n",
    "\n",
    "        # 3D plot for training accuracy\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=1, label=f'Training Accuracy (Epochs {start}-{end})', marker='o', color=train_colors[-1], linewidth=3, markersize=8)\n",
    "        \n",
    "        # 3D plot for validation accuracy\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=2, label=f'Validation Accuracy (Epochs {start}-{end})', marker='^', color=val_colors[-1], linewidth=3, markersize=8)\n",
    "\n",
    "    # Set labels with improved styling\n",
    "    ax.set_xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.set_zlabel('Accuracy Level', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Set title with improved styling\n",
    "    ax.set_title('Training and Validation Accuracy in 3D', fontsize=16, fontweight='bold', color='darkblue')\n",
    "\n",
    "    # Customize the grid and background for better aesthetics\n",
    "    ax.grid(True, color='gray', linestyle='--', linewidth=0.5)\n",
    "    ax.set_facecolor('whitesmoke')\n",
    "    \n",
    "    # Adjust the view angle for better clarity\n",
    "    ax.view_init(30, 45)\n",
    "\n",
    "    # Add a legend with better positioning\n",
    "    ax.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_lines(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:13.282555Z",
     "iopub.status.busy": "2025-01-30T14:17:13.282219Z",
     "iopub.status.idle": "2025-01-30T14:17:13.697813Z",
     "shell.execute_reply": "2025-01-30T14:17:13.696910Z",
     "shell.execute_reply.started": "2025-01-30T14:17:13.282525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_accuracy_with_3d_bubbles(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with 3D bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_zlabel('Accuracy Level')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    z_data = []  # Z-axis for different epoch ranges\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            z_data.append(idx + 1)  # Different z values based on epoch range (1, 2, 3, 4)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles (for train and validation accuracy)\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=idx + 1, label=f'Train Accuracy (Epochs {start}-{end})', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=idx + 1, label=f'Validation Accuracy (Epochs {start}-{end})', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, z_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with 3D Bubbles', fontsize=16, fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_bubbles(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:17:13.698887Z",
     "iopub.status.busy": "2025-01-30T14:17:13.698658Z",
     "iopub.status.idle": "2025-01-30T14:17:14.072448Z",
     "shell.execute_reply": "2025-01-30T14:17:14.071589Z",
     "shell.execute_reply.started": "2025-01-30T14:17:13.698867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_learning_3d(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss in 3D.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # First 3D subplot for accuracy\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.plot(epochs, history_model_net.history['accuracy'], zs=1, label='Train Accuracy', color='blue', linewidth=2)\n",
    "    ax1.plot(epochs, history_model_net.history['val_accuracy'], zs=2, label='Validation Accuracy', color='green', linewidth=2)\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_zlabel(\"Type\")\n",
    "    ax1.set_title(\"Training and Validation Accuracy in 3D\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Second 3D subplot for loss\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.plot(epochs, history_model_net.history['loss'], zs=1, label='Train Loss', color='red', linewidth=2)\n",
    "    ax2.plot(epochs, history_model_net.history['val_loss'], zs=2, label='Validation Loss', color='purple', linewidth=2)\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_zlabel(\"Type\")\n",
    "    ax2.set_title(\"Training and Validation Loss in 3D\")\n",
    "    ax2.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning_3d(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOBILE NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:33:58.128140Z",
     "iopub.status.busy": "2025-01-30T14:33:58.127840Z",
     "iopub.status.idle": "2025-01-30T14:33:58.131975Z",
     "shell.execute_reply": "2025-01-30T14:33:58.131076Z",
     "shell.execute_reply.started": "2025-01-30T14:33:58.128118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# defining some parameters for the loader\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 120\n",
    "img_width = 120\n",
    "\n",
    "# lower resolution images reduce the definition/clarity of certain features in images.\n",
    "# It can make it harder for CNN to learn the features required for classification or detection.\n",
    "# working with 120 x 120 resolution images for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:34:02.731710Z",
     "iopub.status.busy": "2025-01-30T14:34:02.731417Z",
     "iopub.status.idle": "2025-01-30T14:34:03.193895Z",
     "shell.execute_reply": "2025-01-30T14:34:03.193188Z",
     "shell.execute_reply.started": "2025-01-30T14:34:02.731688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 3\n",
    "\n",
    "# Define input dimensions (adjust according to your data)\n",
    "img_height, img_width = 120, 120  # Example dimensions\n",
    "\n",
    "# Load MobileNet base model without top layers\n",
    "mobilenet_base = MobileNet(weights=None, include_top=False)\n",
    "\n",
    "# Define input tensor with specific shape\n",
    "input_tensor = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add MobileNet base model\n",
    "x = mobilenet_base(input_tensor)\n",
    "\n",
    "# Add GlobalAveragePooling2D layer to reduce spatial dimensions\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add Dense layers with BatchNormalization and Dropout for regularization\n",
    "x = Dense(1024, activation='relu')(x)  # Increased units for more capacity\n",
    "x = BatchNormalization()(x)  # BatchNormalization to stabilize training\n",
    "x = Dropout(0.4)(x)  # Increased dropout to prevent overfitting\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # BatchNormalization\n",
    "x = Dropout(0.4)(x)  # Increased dropout\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # BatchNormalization\n",
    "x = Dropout(0.3)(x)  # Moderate dropout\n",
    "\n",
    "# Optional: Add more layers for additional capacity\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # BatchNormalization\n",
    "x = Dropout(0.3)(x)  # Moderate dropout\n",
    "\n",
    "# Output layer\n",
    "output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:34:05.158282Z",
     "iopub.status.busy": "2025-01-30T14:34:05.158004Z",
     "iopub.status.idle": "2025-01-30T14:34:05.162615Z",
     "shell.execute_reply": "2025-01-30T14:34:05.161691Z",
     "shell.execute_reply.started": "2025-01-30T14:34:05.158259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.2,           # Reduce learning rate by half\n",
    "    patience=5,           # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-5,          # Minimum learning rate allowed\n",
    "    verbose=1             # Print a message when the learning rate is reduced\n",
    ")\n",
    "callbacks = [lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:34:08.013556Z",
     "iopub.status.busy": "2025-01-30T14:34:08.013251Z",
     "iopub.status.idle": "2025-01-30T14:34:08.017347Z",
     "shell.execute_reply": "2025-01-30T14:34:08.016599Z",
     "shell.execute_reply.started": "2025-01-30T14:34:08.013531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable graph optimization\n",
    "tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:34:09.835496Z",
     "iopub.status.busy": "2025-01-30T14:34:09.835192Z",
     "iopub.status.idle": "2025-01-30T14:34:09.841317Z",
     "shell.execute_reply": "2025-01-30T14:34:09.840466Z",
     "shell.execute_reply.started": "2025-01-30T14:34:09.835472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:34:10.597125Z",
     "iopub.status.busy": "2025-01-30T14:34:10.596815Z",
     "iopub.status.idle": "2025-01-30T14:34:10.605312Z",
     "shell.execute_reply": "2025-01-30T14:34:10.604485Z",
     "shell.execute_reply.started": "2025-01-30T14:34:10.597098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:34:12.463618Z",
     "iopub.status.busy": "2025-01-30T14:34:12.463274Z",
     "iopub.status.idle": "2025-01-30T14:34:12.467696Z",
     "shell.execute_reply": "2025-01-30T14:34:12.466776Z",
     "shell.execute_reply.started": "2025-01-30T14:34:12.463589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set GPU memory growth to avoid memory fragmentation issues\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:34:32.160774Z",
     "iopub.status.busy": "2025-01-30T14:34:32.160246Z",
     "iopub.status.idle": "2025-01-30T14:40:36.492290Z",
     "shell.execute_reply": "2025-01-30T14:40:36.491420Z",
     "shell.execute_reply.started": "2025-01-30T14:34:32.160726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"GPU is available\")\n",
    "    # Set memory growth for GPU\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize Adam optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# Specify loss function\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "history_model_net = model.fit(\n",
    "                    train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    #steps_per_epoch=100,\n",
    "                    epochs=epochs,\n",
    "                   # callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:36.493880Z",
     "iopub.status.busy": "2025-01-30T14:40:36.493573Z",
     "iopub.status.idle": "2025-01-30T14:40:37.003812Z",
     "shell.execute_reply": "2025-01-30T14:40:37.002868Z",
     "shell.execute_reply.started": "2025-01-30T14:40:36.493853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss with different colors.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_model_net.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history_model_net.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_model_net.history['loss'], label='Train Loss', color='red')\n",
    "    plt.plot(history_model_net.history['val_loss'], label='Validation Loss', color='purple')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:37.005440Z",
     "iopub.status.busy": "2025-01-30T14:40:37.005150Z",
     "iopub.status.idle": "2025-01-30T14:40:37.011234Z",
     "shell.execute_reply": "2025-01-30T14:40:37.010420Z",
     "shell.execute_reply.started": "2025-01-30T14:40:37.005372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:37.012822Z",
     "iopub.status.busy": "2025-01-30T14:40:37.012589Z",
     "iopub.status.idle": "2025-01-30T14:40:41.753160Z",
     "shell.execute_reply": "2025-01-30T14:40:41.752506Z",
     "shell.execute_reply.started": "2025-01-30T14:40:37.012802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluating performance on test set\n",
    "\n",
    "results = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss of the model  is - test \", results[0])\n",
    "print(\"Accuracy of the model is - test\", results[1]*100, \"%\\n\")\n",
    "\n",
    "\n",
    "results = model.evaluate(val_ds)\n",
    "\n",
    "print(\"Loss of the model  is - val \", results[0])\n",
    "print(\"Accuracy of the model is - val\", results[1]*100, \"%\\n\")\n",
    "\n",
    "results = model.evaluate(train_ds)\n",
    "\n",
    "print(\"Loss of the model  is - train \", results[0])\n",
    "print(\"Accuracy of the model is - train\", results[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:41.754282Z",
     "iopub.status.busy": "2025-01-30T14:40:41.754002Z",
     "iopub.status.idle": "2025-01-30T14:40:45.397643Z",
     "shell.execute_reply": "2025-01-30T14:40:45.396816Z",
     "shell.execute_reply.started": "2025-01-30T14:40:41.754259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = np.array([])\n",
    "labels =  np.array([])\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x, verbose=0),axis=1)\n",
    "    predictions = np.concatenate([predictions, y_pred])\n",
    "    labels = np.concatenate([labels, y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:45.398915Z",
     "iopub.status.busy": "2025-01-30T14:40:45.398598Z",
     "iopub.status.idle": "2025-01-30T14:40:45.413340Z",
     "shell.execute_reply": "2025-01-30T14:40:45.412472Z",
     "shell.execute_reply.started": "2025-01-30T14:40:45.398891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(labels,predictions,\n",
    "                           target_names = ['china fan dance', 'Sword Dance', 'dragon dance images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:45.414564Z",
     "iopub.status.busy": "2025-01-30T14:40:45.414241Z",
     "iopub.status.idle": "2025-01-30T14:40:49.701987Z",
     "shell.execute_reply": "2025-01-30T14:40:49.701140Z",
     "shell.execute_reply.started": "2025-01-30T14:40:45.414532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Replace with actual class names)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of rows and columns for the grid\n",
    "rows, cols = 4, 4  \n",
    "\n",
    "# Take a batch of images and labels from the dataset\n",
    "for images, labels in test_ds.take(1):  # Take only one batch\n",
    "    plt.figure(figsize=(12, 12))  # Set figure size\n",
    "\n",
    "    for i in range(min(rows * cols, len(images))):  # Ensure it doesn't exceed dataset size\n",
    "        plt.subplot(rows, cols, i + 1)  # Create a 4-row, 4-column subplot\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert image to uint8 format\n",
    "        plt.axis(\"off\")  # Hide axes\n",
    "\n",
    "        # Get model predictions\n",
    "        predictions = model.predict(images[i][None, ...])  # Get prediction probabilities\n",
    "        predicted_class = np.argmax(predictions)  # Get class index\n",
    "        confidence = np.max(predictions) * 100  # Get confidence in percentage\n",
    "\n",
    "        # Set title with class name and confidence\n",
    "        plt.title(f\"{class_names[predicted_class]}\\n{confidence:.2f}%\", fontsize=10, color=\"red\")\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()  # Display the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:49.704270Z",
     "iopub.status.busy": "2025-01-30T14:40:49.704050Z",
     "iopub.status.idle": "2025-01-30T14:40:49.707674Z",
     "shell.execute_reply": "2025-01-30T14:40:49.706850Z",
     "shell.execute_reply.started": "2025-01-30T14:40:49.704251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:49.708979Z",
     "iopub.status.busy": "2025-01-30T14:40:49.708788Z",
     "iopub.status.idle": "2025-01-30T14:40:50.671799Z",
     "shell.execute_reply": "2025-01-30T14:40:50.670902Z",
     "shell.execute_reply.started": "2025-01-30T14:40:49.708961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize empty lists for true labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through the test dataset to obtain predictions\n",
    "for x, y in val_ds:\n",
    "    y_pred = np.argmax(model.predict(x), axis=1)\n",
    "    true_labels.extend(y.numpy())\n",
    "    predicted_labels.extend(y_pred)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Print classification report\n",
    "#print(classification_report(true_labels, predicted_labels,\n",
    "#                            target_names=[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:50.673647Z",
     "iopub.status.busy": "2025-01-30T14:40:50.673239Z",
     "iopub.status.idle": "2025-01-30T14:40:50.957588Z",
     "shell.execute_reply": "2025-01-30T14:40:50.956624Z",
     "shell.execute_reply.started": "2025-01-30T14:40:50.673619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix (cm):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        cmap = 'Blues', \n",
    "        linecolor = 'black', \n",
    "        linewidth = 1, \n",
    "        annot = True, \n",
    "        fmt = '', \n",
    "        xticklabels = class_names, \n",
    "        yticklabels = class_names)\n",
    "    \n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:50.958884Z",
     "iopub.status.busy": "2025-01-30T14:40:50.958617Z",
     "iopub.status.idle": "2025-01-30T14:40:51.145172Z",
     "shell.execute_reply": "2025-01-30T14:40:51.144236Z",
     "shell.execute_reply.started": "2025-01-30T14:40:50.958859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix_3d(cm, class_names):\n",
    "    \"\"\"\n",
    "    Plots a 3D surface plot for the confusion matrix.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create the X and Y grid for the confusion matrix\n",
    "    x, y = np.meshgrid(np.arange(cm.shape[0]), np.arange(cm.shape[1]))\n",
    "\n",
    "    # Plotting the surface\n",
    "    ax.plot_surface(x, y, cm, cmap='Blues', edgecolor='black', linewidth=1)\n",
    "\n",
    "    # Annotate the surface with text (values from the confusion matrix)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(x[i, j], y[i, j], cm[i, j], str(cm[i, j]), color='black', fontsize=12, ha='center')\n",
    "\n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_zlabel('Count')\n",
    "\n",
    "    # Set ticks for X and Y axes based on class names\n",
    "    ax.set_xticks(np.arange(cm.shape[1]))\n",
    "    ax.set_yticks(np.arange(cm.shape[0]))\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title('Confusion Matrix in 3D')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "#[\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]\n",
    "# Example usage:\n",
    "# Assuming you have a confusion matrix `cm` and class names in `class_names`\n",
    "class_names = ['china fan dance', 'Sword Dance', 'dragon dance images']  # Modify with your actual class names\n",
    "plot_confusion_matrix_3d(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:51.146302Z",
     "iopub.status.busy": "2025-01-30T14:40:51.146062Z",
     "iopub.status.idle": "2025-01-30T14:40:51.653230Z",
     "shell.execute_reply": "2025-01-30T14:40:51.652294Z",
     "shell.execute_reply.started": "2025-01-30T14:40:51.146281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define class names (Modify based on your dataset)\n",
    "class_names = [\"china fan dance\", \"Sword Dance\", \"dragon dance images\"]  # Modify based on your dataset\n",
    "\n",
    "# Number of epochs for plotting (replace with actual epoch count)\n",
    "epochs = np.arange(1, 11)  # Example: 10 epochs\n",
    "\n",
    "# Create a larger plot\n",
    "fig, ax = plt.subplots(figsize=(16, 12))  # Enlarged plot size\n",
    "\n",
    "# Set labels for axes and title\n",
    "ax.set_xlabel('Epochs', fontsize=14, weight='bold')\n",
    "ax.set_ylabel('Confidence (%)', fontsize=14, weight='bold')\n",
    "ax.set_title('Model Accuracy with Confidence Bubbles', fontsize=16, weight='bold')\n",
    "\n",
    "# Variables to store bubble data\n",
    "x_data = []\n",
    "y_data = []\n",
    "sizes = []  # Bubble sizes (confidence or any other measure)\n",
    "colors = []  # Bubble colors (can represent confidence)\n",
    "\n",
    "# Generate random data for demonstration\n",
    "# Replace this section with real model predictions for each epoch\n",
    "for epoch in epochs:\n",
    "    for class_idx in range(len(class_names)):\n",
    "        # Simulating confidence for each class in each epoch\n",
    "        confidence = np.random.uniform(0.60, 1.00) * 100  # Random confidence between 60 and 100%\n",
    "        \n",
    "        # Store the data for plotting\n",
    "        x_data.append(epoch)\n",
    "        y_data.append(confidence)\n",
    "        sizes.append(confidence * 25)  # Increased bubble size (scaled more)\n",
    "        colors.append(confidence)  # Set color based on confidence\n",
    "\n",
    "# Scatter plot with bubbles\n",
    "scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='plasma', alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Add color bar for confidence\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='Confidence %')\n",
    "cbar.set_ticks([0, 25, 50, 75, 100])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Adjust spacing for labels to avoid overlap and keep labels inside the plot\n",
    "for i in range(len(x_data)):\n",
    "    # Offset y-position to avoid going outside the plotting area\n",
    "    label_x = x_data[i]\n",
    "    label_y = y_data[i] + 5  # Adjust this offset if necessary\n",
    "\n",
    "    # Check if the label is too close to the top or bottom and adjust\n",
    "    if label_y > 100:  # If label goes above the upper limit\n",
    "        label_y = 95  # Place label a little below 100\n",
    "    elif label_y < 10:  # If label is too close to the bottom\n",
    "        label_y = 15  # Place label a little above 0\n",
    "    \n",
    "    ax.text(label_x, label_y, f'{class_names[x_data[i] % len(class_names)]}\\n{y_data[i]:.1f}%', \n",
    "            ha='center', fontsize=8, color='black', weight='bold', fontstyle='italic', \n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))  # Background for better readability\n",
    "\n",
    "# Adjusting grid for better presentation\n",
    "ax.set_xticks(epochs)\n",
    "ax.set_yticks(np.arange(0, 110, 10))\n",
    "ax.set_yticklabels(np.arange(0, 110, 10), fontsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Increase space between labels and bubbles\n",
    "ax.margins(x=0.05, y=0.1)\n",
    "\n",
    "# Tight layout to prevent overlap\n",
    "plt.tight_layout(pad=5.0)  # Increased padding for better spacing\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:40:51.654539Z",
     "iopub.status.busy": "2025-01-30T14:40:51.654217Z",
     "iopub.status.idle": "2025-01-30T14:40:52.097080Z",
     "shell.execute_reply": "2025-01-30T14:40:52.096223Z",
     "shell.execute_reply.started": "2025-01-30T14:40:51.654510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 2D plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for start, end in epoch_ranges:\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with Bubbles')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:49:05.447377Z",
     "iopub.status.busy": "2025-01-30T14:49:05.447082Z",
     "iopub.status.idle": "2025-01-30T14:49:08.343585Z",
     "shell.execute_reply": "2025-01-30T14:49:08.342590Z",
     "shell.execute_reply.started": "2025-01-30T14:49:05.447353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_bubbles_separated(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Variables to store bubble data\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        sizes = []  # Bubble sizes (based on accuracy)\n",
    "        colors = []  # Bubble colors (for visualization)\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Train Accuracy Epochs {start}-{end}', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy Epochs {start}-{end}', marker='x', linestyle='-', color='green')\n",
    "\n",
    "        # Scatter plot with bubbles\n",
    "        scatter = ax.scatter(x_data, y_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add color bar for accuracy\n",
    "        plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_bubbles_separated(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:49:12.082207Z",
     "iopub.status.busy": "2025-01-30T14:49:12.081880Z",
     "iopub.status.idle": "2025-01-30T14:49:13.256837Z",
     "shell.execute_reply": "2025-01-30T14:49:13.255901Z",
     "shell.execute_reply.started": "2025-01-30T14:49:12.082180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_solid_lines(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate subplots for each epoch range (1-25, 26-50, 51-75, 76-100),\n",
    "    using solid lines to represent the accuracies.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create subplots for each epoch range\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2x2 grid for 4 subplots\n",
    "    axes = axes.flatten()  # Flatten to easily iterate over\n",
    "\n",
    "    # Iterate through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Plot the lines for training and validation accuracy with new colors\n",
    "        ax.plot(epoch_range, train_accuracy_range, label=f'Training Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='darkorange', linewidth=3)\n",
    "        ax.plot(epoch_range, val_accuracy_range, label=f'Validation Accuracy (Epochs {start}-{end})', linestyle='-', marker='o', color='mediumseagreen', linewidth=3)\n",
    "\n",
    "        # Set labels for axes\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        \n",
    "        # Add title and legend\n",
    "        ax.set_title(f'Training and Validation Accuracy (Epochs {start}-{end})')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_solid_lines(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:49:17.175887Z",
     "iopub.status.busy": "2025-01-30T14:49:17.175586Z",
     "iopub.status.idle": "2025-01-30T14:49:17.557691Z",
     "shell.execute_reply": "2025-01-30T14:49:17.556744Z",
     "shell.execute_reply.started": "2025-01-30T14:49:17.175864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def plot_accuracy_with_3d_lines(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy in separate 3D subplots for each epoch range (1-25, 26-50, 51-75, 76-100).\n",
    "    Adds enhancements such as color gradients for a stunning 3D effect.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a figure for the 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')  # 3D subplot\n",
    "    \n",
    "    # Set the colormap and normalize the values for color gradients\n",
    "    cmap = cm.viridis  # You can change this to any other colormap such as 'plasma', 'inferno', etc.\n",
    "    norm = Normalize(vmin=1, vmax=100)\n",
    "\n",
    "    # Loop through each epoch range and plot on corresponding subplot\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Color gradient based on epoch number\n",
    "        train_colors = cmap(norm(epoch_range))  # Apply colormap to training accuracy\n",
    "        val_colors = cmap(norm(epoch_range))    # Apply colormap to validation accuracy\n",
    "\n",
    "        # 3D plot for training accuracy\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=1, label=f'Training Accuracy (Epochs {start}-{end})', marker='o', color=train_colors[-1], linewidth=3, markersize=8)\n",
    "        \n",
    "        # 3D plot for validation accuracy\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=2, label=f'Validation Accuracy (Epochs {start}-{end})', marker='^', color=val_colors[-1], linewidth=3, markersize=8)\n",
    "\n",
    "    # Set labels with improved styling\n",
    "    ax.set_xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.set_zlabel('Accuracy Level', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Set title with improved styling\n",
    "    ax.set_title('Training and Validation Accuracy in 3D', fontsize=16, fontweight='bold', color='darkblue')\n",
    "\n",
    "    # Customize the grid and background for better aesthetics\n",
    "    ax.grid(True, color='gray', linestyle='--', linewidth=0.5)\n",
    "    ax.set_facecolor('whitesmoke')\n",
    "    \n",
    "    # Adjust the view angle for better clarity\n",
    "    ax.view_init(30, 45)\n",
    "\n",
    "    # Add a legend with better positioning\n",
    "    ax.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_lines(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:49:29.239071Z",
     "iopub.status.busy": "2025-01-30T14:49:29.238774Z",
     "iopub.status.idle": "2025-01-30T14:49:29.668245Z",
     "shell.execute_reply": "2025-01-30T14:49:29.667361Z",
     "shell.execute_reply.started": "2025-01-30T14:49:29.239049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_accuracy_with_3d_bubbles(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy with 3D bubbles for different epoch ranges.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Split the epochs and accuracy into different ranges (1-25, 26-50, 51-75, 76-100)\n",
    "    epoch_ranges = [(1, 25), (26, 50), (51, 75), (76, 100)]\n",
    "    accuracies = {\n",
    "        'train': history_model_net.history['accuracy'],\n",
    "        'val': history_model_net.history['val_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Set labels for axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_zlabel('Accuracy Level')\n",
    "    \n",
    "    # Variables to store bubble data\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    z_data = []  # Z-axis for different epoch ranges\n",
    "    sizes = []  # Bubble sizes (based on accuracy)\n",
    "    colors = []  # Bubble colors (for visualization)\n",
    "    \n",
    "    # Plot training accuracy with bubbles and lines for each epoch range\n",
    "    for idx, (start, end) in enumerate(epoch_ranges):\n",
    "        # Get the relevant epoch range\n",
    "        train_accuracy_range = accuracies['train'][start-1:end]\n",
    "        val_accuracy_range = accuracies['val'][start-1:end]\n",
    "        epoch_range = epochs[start-1:end]\n",
    "        \n",
    "        # Add bubbles for train accuracy\n",
    "        for i, acc in enumerate(train_accuracy_range):\n",
    "            x_data.append(epoch_range[i])\n",
    "            y_data.append(acc)\n",
    "            z_data.append(idx + 1)  # Different z values based on epoch range (1, 2, 3, 4)\n",
    "            sizes.append(acc * 800)  # Bubble size based on accuracy\n",
    "            colors.append(acc)  # Color based on accuracy\n",
    "        \n",
    "        # Add lines between bubbles (for train and validation accuracy)\n",
    "        ax.plot(epoch_range, train_accuracy_range, zs=idx + 1, label=f'Train Accuracy (Epochs {start}-{end})', marker='o', linestyle='-', color='blue')\n",
    "        ax.plot(epoch_range, val_accuracy_range, zs=idx + 1, label=f'Validation Accuracy (Epochs {start}-{end})', marker='x', linestyle='-', color='green')\n",
    "\n",
    "    # Scatter plot with bubbles\n",
    "    scatter = ax.scatter(x_data, y_data, z_data, s=sizes, c=colors, cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Add color bar for accuracy\n",
    "    plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "\n",
    "    # Add title and legend\n",
    "    ax.set_title('Training and Validation Accuracy with 3D Bubbles', fontsize=16, fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_accuracy_with_3d_bubbles(history_model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:49:32.980820Z",
     "iopub.status.busy": "2025-01-30T14:49:32.980528Z",
     "iopub.status.idle": "2025-01-30T14:49:33.384765Z",
     "shell.execute_reply": "2025-01-30T14:49:33.383954Z",
     "shell.execute_reply.started": "2025-01-30T14:49:32.980799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting module\n",
    "\n",
    "def plot_learning_3d(history_model_net):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy and loss in 3D.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history_model_net.history['accuracy']) + 1)\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # First 3D subplot for accuracy\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.plot(epochs, history_model_net.history['accuracy'], zs=1, label='Train Accuracy', color='blue', linewidth=2)\n",
    "    ax1.plot(epochs, history_model_net.history['val_accuracy'], zs=2, label='Validation Accuracy', color='green', linewidth=2)\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_zlabel(\"Type\")\n",
    "    ax1.set_title(\"Training and Validation Accuracy in 3D\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Second 3D subplot for loss\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.plot(epochs, history_model_net.history['loss'], zs=1, label='Train Loss', color='red', linewidth=2)\n",
    "    ax2.plot(epochs, history_model_net.history['val_loss'], zs=2, label='Validation Loss', color='purple', linewidth=2)\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_zlabel(\"Type\")\n",
    "    ax2.set_title(\"Training and Validation Loss in 3D\")\n",
    "    ax2.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model history\n",
    "plot_learning_3d(history_model_net)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6573644,
     "sourceId": 10617473,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6574697,
     "sourceId": 10618908,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
